# [arXiv Digest] 2025-07-02


## 1. Enhancing LLM Agent Safety via Causal Influence Prompting
- **Authors:** Dongyoon Hahm, Woogyeol Jin, June Suk Choi, Sungsoo Ahn, Kimin Lee
- **URL:** https://arxiv.org/abs/2507.00979
- **요약 (영문):** autonomous agents powered by large language models continue to demonstrate potential across various assistive tasks . we introduce CIP, a novel technique that leverages causal influence diagrams (CIDs) to identify and mitigate risks arising from agent decision-making .
- **요약 (한글):** 대규모 언어 모델을 기반으로 하는 자율 에이전트는 다양한 지원 작업에서 계속해서 잠재력을 입증하고 있으며, 인과 관계 영향도(CID)를 활용하여 에이전트 의사 결정에서 발생하는 위험을 식별하고 완화하는 새로운 기술인 CIP를 소개합니다.

## 2. Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact
- **Authors:** Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, Philip Torr, Seyedali Mirjalili
- **URL:** https://arxiv.org/abs/2507.00951
- **요약 (영문):** despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, these systems remain fundamentally limited by their reliance on token-level prediction . this paper offers a cross-disciplinary synthesis of AGI development .
- **요약 (한글):** GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4 및 Grok 3와 같은 모델의 기능이 향상되었음에도 불구하고 이러한 시스템은 토큰 수준 예측에 의존한다는 근본적인 한계가 있습니다. 이 논문에서는 AGI 개발에 대한 여러 분야의 종합적인 정보를 제공합니다.

## 3. SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents
- **Authors:** Siyuan Liang, Tianmeng Fang, Zhe Liu, Aishan Liu, Yan Xiao, Jinyuan He, Ee-Chien Chang, Xiaochun Cao
- **URL:** https://arxiv.org/abs/2507.00841
- **요약 (영문):** a wide application of multimodal foundation models in intelligent agent systems is increasingly relying on such large model-driven agents . attacks may induce the agents to bypass the original behavioral constraints through specific inputs .
- **요약 (한글):** 지능형 에이전트 시스템에서 멀티모달 기반 모델의 광범위한 적용은 이러한 대규모 모델 기반 에이전트에 점점 더 의존하고 있습니다. 공격은 특정 입력을 통해 에이전트가 원래의 행동 제약을 우회하도록 유도할 수 있습니다.

## 4. Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess
- **Authors:** Dongyoon Hwang, Hojoon Lee, Jaegul Choo, Dongmin Park, Jongho Park
- **URL:** https://arxiv.org/abs/2507.00726
- **요약 (영문):** reinforcement learning (RL) for large language models (LLMs) has shown promise in mathematical reasoning . to this end, we leverage a chess-pretrained action-value network .
- **요약 (한글):** 대규모 언어 모델(LLM)을 위한 강화 학습(RL)은 수학적 추론에서 가능성을 보였습니다. 이를 위해 체스로 사전 학습된 행동 값 네트워크를 활용합니다.

## 5. Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning
- **Authors:** Maggie Huan, Yuetai Li, Tuney Zheng, Xiaoyu Xu, Seungone Kim, Minxin Du, Radha Poovendran, Graham Neubig, Xiang Yue
- **URL:** https://arxiv.org/abs/2507.00432
- **요약 (영문):** we evaluate over 20 open-weight reasoning-tuned models across a broad range of tasks, including math, scientific QA, agent planning, coding, and standard in math . if these gains reflect broader problem-solving ability or narrow overfitting?
- **요약 (한글):** 수학, 과학 QA, 에이전트 계획, 코딩, 수학 표준 등 광범위한 작업에서 20개 이상의 개방형 추론 조정 모델을 평가합니다. 이러한 이득이 광범위한 문제 해결 능력을 반영하는지 아니면 좁은 과적합을 반영하는지?

## 6. ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context
- **Authors:** Joongwon Kim, Anirudh Goyal, Liang Tan, Hannaneh Hajishirzi, Srinivasan Iyer, Tianlu Wang
- **URL:** https://arxiv.org/abs/2507.00417
- **요약 (영문):** the "Autoregressive Search-Taught Reasoner" is a framework for training language models to reason like search algorithms . the framework combines self-reflection, backtracking, and exploration in their outputs .
- **요약 (한글):** "자동 회귀 검색 학습 추론기"는 검색 알고리즘처럼 추론하도록 언어 모델을 훈련시키는 프레임워크입니다. 이 프레임워크는 자기 반영, 역추적 및 탐색을 출력에 결합합니다.

## 7. GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning
- **Authors:** Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, Shuaiqi Duan, Weihan Wang, Yan Wang, Yean Cheng, Zehai He, Zhe Su, Zhen Yang, Ziyang Pan, Aohan Zeng, Baoxu Wang, Boyan Shi, Changyu Pang, Chenhui Zhang, Da Yin, Fan Yang, Guoqing Chen, Jiazheng Xu, Jiali Chen, Jing Chen, Jinhao Chen, Jinghao Lin, Jinjiang Wang, Junjie Chen, Leqi Lei, Leyi Pan, Mingzhi Zhang, Qinkai Zheng, Sheng Yang, Shi Zhong, Shiyu Huang, Shuyuan Zhao, Siyan Xue, Shangqin Tu, Shengbiao Meng, Tianshu Zhang, Tianwei Luo, Tianxiang Hao, Tianle Gong, Wenkai Li, Wei Jia, Xin Lyu, Xuancheng Huang, Yanling Wang, Yadong Xue, Yanfeng Wang, Yifan An, Yifan Du, Yiming Shi, Yiheng Huang, Yilin Niu, Yuan Wang, Yuanchang Yue, Yuchen Li, Yutao Zhang, Yuxuan Zhang, Zhanxiao Du, Zhenyu Hou, Zhao Xue, Zhengxiao Du, Zihan Wang, Peng Zhang, Debing Liu, Bin Xu, Juanzi Li, Minlie Huang, Yuxiao Dong, Jie Tang
- **URL:** https://arxiv.org/abs/2507.01006
- **요약 (영문):** we present a vision-language model (GLM-4.1V-Thinking) designed to advance general-purpose multimodal reasoning . we first develop a capable vision foundation model with significant potential through large-scale pre-training .
- **요약 (한글):** 범용 멀티모달 추론을 발전시키기 위해 설계된 비전 언어 모델(GLM-4.1V-Thinking)을 제시합니다. 먼저 대규모 사전 훈련을 통해 상당한 잠재력을 가진 유능한 비전 기반 모델을 개발합니다.

## 8. Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations
- **Authors:** Shivansh Patel, Shraddhaa Mohan, Hanlin Mai, Unnat Jain, Svetlana Lazebnik, Yunzhu Li
- **URL:** https://arxiv.org/abs/2507.00990
- **요약 (영문):** a video diffusion model generates potential demonstration videos . a vision-language model filters out results that do not follow the command .
- **요약 (한글):** 비디오 확산 모델은 잠재적인 데모 비디오를 생성합니다. 비전 언어 모델은 명령을 따르지 않는 결과를 필터링합니다.

## 9. Reasoning as an Adaptive Defense for Safety
- **Authors:** Taeyoun Kim, Fahim Tajwar, Aditi Raghunathan, Aviral Kumar
- **URL:** https://arxiv.org/abs/2507.00971
- **요약 (영문):** methods that adaptively allocate test-time compute have advanced LLM performance on easy to verify domains such as math and code . we build a recipe called $textitTARS$ that trains models to reason about safety .
- **요약 (한글):** 테스트 시간 계산을 적응적으로 할당하는 메서드는 수학 및 코드와 같이 검증하기 쉬운 도메인에서 LLM 성능을 향상시켰습니다. 우리는 안전성에 대해 추론하도록 모델을 훈련하는 $textitTARS$라는 레시피를 구축합니다.

## 10. From Sentences to Sequences: Rethinking Languages in Biological System
- **Authors:** Ke Liu, Shuanke Shen, Hao Chen
- **URL:** https://arxiv.org/abs/2507.00953
- **요약 (영문):** the paradigm of large language models in natural language processing (NLP) has also shown promise in modeling biological languages, including proteins, RNA, and DNA . both the auto-regressive generation paradigm and evaluation metrics have been transferred from NLP to biological sequence modeling .
- **요약 (한글):** 자연어 처리(NLP)의 대규모 언어 모델 패러다임은 단백질, RNA, DNA를 포함한 생물학적 언어 모델링에서도 가능성을 보였습니다. 자동 회귀 생성 패러다임과 평가 메트릭 모두 NLP에서 생물학적 서열 모델링으로 이전되었습니다.

## 11. WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks
- **Authors:** Zihao Sun, Meng Fang, Ling Chen
- **URL:** https://arxiv.org/abs/2507.00938
- **요약 (영문):** WebArXiv is a static and time-invariant benchmark . the benchmark includes 275 web-based tasks . it ensures reproducible a real website .
- **요약 (한글):** WebArXiv는 정적이고 시간에 변하지 않는 벤치마크로, 275개의 웹 기반 작업을 포함하며 실제 웹사이트를 재현할 수 있습니다.

## 12. Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications
- **Authors:** Jindong Han, Yansong Ning, Zirui Yuan, Hang Ni, Fan Liu, Tengfei Lyu, Hao Liu
- **URL:** https://arxiv.org/abs/2507.00914
- **요약 (영문):** the long-standing vision of intelligent cities is to create efficient, livable, and sustainable urban environments using big data and artificial intelligence technologies . the advent of Large Language Models (LLMs) has opened new ways toward realizing this vision .
- **요약 (한글):** 지능형 도시의 오랜 비전은 빅데이터와 인공 지능 기술을 사용하여 효율적이고 살기 좋으며 지속 가능한 도시 환경을 조성하는 것입니다. 대규모 언어 모델(LLM)의 출현으로 이러한 비전을 실현할 수 있는 새로운 길이 열렸습니다.

## 13. The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses
- **Authors:** Fabio Correa Xavier
- **URL:** https://arxiv.org/abs/2507.00907
- **요약 (영문):** sensorial zero trust is a new security mindset . the concept is based on generative artificial intelligence . this article presents a scientific analysis of the need to systematically doubt information .
- **요약 (한글):** 감각적 제로 트러스트는 새로운 보안 사고방식입니다. 이 개념은 생성적 인공 지능을 기반으로 합니다. 이 기사에서는 정보를 체계적으로 의심할 필요성에 대한 과학적 분석을 제시합니다.

## 14. Stylometry recognizes human and LLM-generated texts in short samples
- **Authors:** Karol Przystalski, Jan K. Argasiński, Iwona Grabska-Gradzińska, Jeremi K. Ochab
- **URL:** https://arxiv.org/abs/2507.00838
- **요약 (영문):** the paper explores stylometry as a method to distinguish between texts created by Large Language Models (LLMs) and humans . the method is used extensively to characterise the style and attribute authorship of texts .
- **요약 (한글):** 이 논문에서는 대규모 언어 모델(LLM)과 사람이 만든 텍스트를 구별하는 방법으로서 스타일 메트릭을 탐구합니다. 이 방법은 텍스트의 스타일을 특성화하고 저작자를 파악하는 데 광범위하게 사용됩니다.

## 15. HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning
- **Authors:** Zhi Jing, Siyuan Yang, Jicong Ao, Ting Xiao, Yugang Jiang, Chenjia Bai
- **URL:** https://arxiv.org/abs/2507.00833
- **요약 (영문):** humanoid robots are equipped with dual arms and dexterous hands . simulation tasks and demonstrations are lacking for robot-arm platforms .
- **요약 (한글):** 휴머노이드 로봇은 양팔과 민첩한 손을 갖추고 있습니다. 로봇 팔 플랫폼에 대한 시뮬레이션 작업 및 데모가 부족합니다.

## 16. CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs
- **Authors:** Jiaming Zhang, Rui Hu, Qing Guo, Wei Yang Bryan Lim
- **URL:** https://arxiv.org/abs/2507.00817
- **요약 (영문):** video multimodal Large Language Models (V-MLLMs) have shown impressive capabilities in temporal reasoning and cross-modal understanding . their vulnerability to adversarial attacks remains underexplored due to unique challenges .
- **요약 (한글):** 비디오 멀티모달 대규모 언어 모델(V-MLLM)은 시간적 추론과 모달 간 이해에서 인상적인 능력을 보여 왔지만, 고유한 문제로 인해 적대적 공격에 대한 취약성은 아직 밝혀지지 않았습니다.

## 17. Many LLMs Are More Utilitarian Than One
- **Authors:** Anita Keshmirian, Razan Baltaji, Babak Hemmatian, Hadi Asghari, Lav R. Varshney
- **URL:** https://arxiv.org/abs/2507.00814
- **요약 (영문):** moral judgment is integral to large language model (LLM) alignment and social reasoning . we study whether a similar dynamic emerges in multi-agent LLM systems .
- **요약 (한글):** 도덕적 판단은 대규모 언어 모델(LLM) 정렬과 사회적 추론에 필수적인 요소입니다. 우리는 다중 에이전트 LLM 시스템에서도 유사한 역학 관계가 나타나는지 연구합니다.

## 18. LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing
- **Authors:** Daniel Fein, Sebastian Russo, Violet Xiang, Kabir Jolly, Rafael Rafailov, Nick Haber
- **URL:** https://arxiv.org/abs/2507.00769
- **요약 (영문):** litBench is the first standardized benchmark and paired dataset for creative writing verification . it includes a held-out test set of 2,480 words .
- **요약 (한글):** litBench는 창의적 글쓰기 검증을 위한 최초의 표준화된 벤치마크 및 짝을 이루는 데이터 세트입니다. 여기에는 2,480개의 단어로 구성된 홀드아웃 테스트 세트가 포함되어 있습니다.

## 19. SAFER: Probing Safety in Reward Models with Sparse Autoencoder
- **Authors:** Sihang Li, Wei Shi, Ziyuan Xie, Tao Liang, Guojun Ma, Xiang Wang
- **URL:** https://arxiv.org/abs/2507.00665
- **요약 (영문):** sparse Autoencoder for Enhanced Reward model is a novel framework for interpreting and improving reward models through mechanistic analysis . we uncover human-interpretable features in reward model activations, enabling insight into safety-relevant features .
- **요약 (한글):** 향상된 보상 모델을 위한 스파스 자동 인코더는 기계론적 분석을 통해 보상 모델을 해석하고 개선하기 위한 새로운 프레임워크입니다. 보상 모델 활성화에서 사람이 해석할 수 있는 특징을 발견하여 안전 관련 기능에 대한 인사이트를 얻을 수 있습니다.

## 20. Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity
- **Authors:** Jacopo Nudo, Mario Edoardo Pandolfo, Edoardo Loru, Mattia Samory, Matteo Cinelli, Walter Quattrociocchi
- **URL:** https://arxiv.org/abs/2507.00657
- **요약 (영문):** we construct LLM agents based on 1,186 real users . agents are initialized either with minimal ideological cues (Zero Shot) or recent tweet history (Few Shot), allowing one-to-one comparisons .
- **요약 (한글):** 1,186명의 실제 사용자를 기반으로 LLM 에이전트를 구축합니다. 에이전트는 최소한의 이념적 단서(제로 샷) 또는 최근 트윗 기록(몇 샷)으로 초기화되어 일대일 비교가 가능합니다.

## 21. Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models
- **Authors:** Yilun Zhang
- **URL:** https://arxiv.org/abs/2507.00653
- **요약 (영문):** existing optimization strategies are effective, but lack a guiding cognitive theory to manage the inference process itself . this paper aims to bridge this gap by introducing a novel paradigm: the Cognitive Load-Aware Inference framework .
- **요약 (한글):** 기존의 최적화 전략은 효과적이지만 추론 과정 자체를 관리할 수 있는 인지 이론이 부족합니다. 이 논문은 새로운 패러다임인 인지 부하 인식 추론 프레임워크를 도입하여 이러한 격차를 해소하는 것을 목표로 합니다.

## 22. Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies
- **Authors:** Tao Xiong, Xavier Hu, Wenyan Fan, Shengyu Zhang
- **URL:** https://arxiv.org/abs/2507.00606
- **요약 (영문):** large language models excel in complex tasks through advanced prompting techniques . but their reliance on manually crafted, task-specific prompts limits adaptability and efficiency . we introduce Mixture of Reasoning .
- **요약 (한글):** 대규모 언어 모델은 고급 프롬프트 기술을 통해 복잡한 작업에 탁월하지만 수동으로 제작된 작업별 프롬프트에 의존하기 때문에 적응성과 효율성이 제한됩니다. 저희는 혼합 추론을 소개합니다.

## 23. TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification
- **Authors:** Miriam Anschütz, Ekaterina Gikalo, Niklas Herbster, Georg Groh
- **URL:** https://arxiv.org/abs/2507.00579
- **요약 (영문):** most of the research on hallucinations focuses on English data, neglecting the multilingual nature of LLMs . this paper describes our submission to the SemEval-2025 Task-3 - Mu-SHROOM .
- **요약 (한글):** 환각에 대한 대부분의 연구는 영어 데이터에 초점을 맞추고 있으며, LLM의 다국어 특성을 무시하고 있습니다. 이 논문에서는 SemEval-2025 Task-3 - Mu-SHROOM 에 제출한 내용을 설명합니다.

## 24. Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation
- **Authors:** Feng Lin, Marco Chen, Haokui Zhang, Xiaotian Yu, Guangming Lu, Rong Xiao
- **URL:** https://arxiv.org/abs/2507.00537
- **요약 (영문):** this paper studies the role of attention heads in CLIP's image encoder . we hypothesize that certain attention heads negatively affect final representations and that ablating them can improve performance .
- **요약 (한글):** 이 논문은 CLIP의 이미지 인코더에서 주의 헤드의 역할을 연구합니다. 특정 주의 헤드가 최종 표현에 부정적인 영향을 미치고 이를 제거하면 성능을 향상시킬 수 있다는 가설을 세웁니다.

## 25. Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving
- **Authors:** Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo
- **URL:** https://arxiv.org/abs/2507.00525
- **요약 (영문):** existing vision-language models often struggle to capture user intent in real-world scenarios . box-QAymo is a box-referring dataset and benchmark designed to evaluate and evaluate user-driven queries .
- **요약 (한글):** 기존 비전 언어 모델은 실제 시나리오에서 사용자 의도를 파악하는 데 어려움을 겪는 경우가 많습니다. box-QAymo는 사용자 중심 쿼리를 평가하고 평가하도록 설계된 박스 참조 데이터 세트 및 벤치마크입니다.

## 26. TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search
- **Authors:** To Eun Kim, João Coelho, Gbemileke Onilude, Jai Singh
- **URL:** https://arxiv.org/abs/2507.00509
- **요약 (영문):** the integration of advertisements into generated responses presents both commercial opportunities and challenges for user experience . generative systems blur the boundary between informational content and promotional material, raising concerns around transparency and trust .
- **요약 (한글):** 생성된 반응에 광고를 통합하면 상업적 기회와 사용자 경험에 대한 과제가 동시에 발생합니다. 생성 시스템은 정보 콘텐츠와 홍보 자료 사이의 경계를 모호하게 만들어 투명성과 신뢰에 대한 우려를 불러일으킵니다.

## 27. Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms
- **Authors:** Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri
- **URL:** https://arxiv.org/abs/2507.00491
- **요약 (영문):** cAI systems are typically composed of deep neural networks (DNNs), transformers, and large language models (LLMs), exhibiting a high degree of computational diversity and dynamic workload variation . existing mobile edge AI inference strategies manag .
- **요약 (한글):** cAI 시스템은 일반적으로 심층 신경망(DNN), 트랜스포머, 대규모 언어 모델(LLM)로 구성되어 높은 수준의 계산 다양성과 동적 워크로드 변화를 나타내며, 기존 모바일 엣지 AI 추론 전략은 .

## 28. Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs
- **Authors:** Mohammad Firas Sada, John J. Graham, Elham E Khoda, Mahidhar Tatineni, Dmitry Mishin, Rajesh K. Gupta, Rick Wagner, Larry Smarr, Thomas A. DeFanti, Frank Würthwein
- **URL:** https://arxiv.org/abs/2507.00418
- **요약 (영문):** a total of 15 open-source LLMs, ranging from 117 million to 90 billion parameters, are served using the vLLM framework . the QAic inference cards appear to be energy efficient .
- **요약 (한글):** 1억 1,700만 개에서 900억 개의 파라미터에 이르는 총 15개의 오픈 소스 LLM이 vLLM 프레임워크를 사용하여 제공되며, QAic 추론 카드가 에너지 효율이 높은 것으로 보입니다.

## 29. iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing
- **Authors:** Xikai Sun, Fan Dang, Kebin Liu, Xin Miao, Zihao Yang, Haimo Lu, Yawen Zheng, Yunhao Liu
- **URL:** https://arxiv.org/abs/2507.00378
- **요약 (영문):** large language models (LLMs) have demonstrated impressive text comprehension and code generation abilities . this paper proposes iPanda, the first end-to-end framework that leverages LLMs .
- **요약 (한글):** 대규모 언어 모델(LLM)은 인상적인 텍스트 이해 및 코드 생성 능력을 보여주었습니다. 이 백서에서는 LLM을 활용하는 최초의 엔드투엔드 프레임워크인 iPanda를 제안합니다.

## 30. An AST-guided LLM Approach for SVRF Code Synthesis
- **Authors:** Abanoub E. Abdelmalak, Mohamed A. Elsayed, David Abercrombie, Ilhami Torunoglu
- **URL:** https://arxiv.org/abs/2507.00352
- **요약 (영문):** standard verification rule format (SVRF) is essential for semiconductor applications like Design Rule Check (DRC), Layout Versus Schematic (LVS) and Optical Proximity Correction (OPC) it faces challenges as advancing nodes create complex design rules that render traditional SVRF development ineffective .
- **요약 (한글):** 표준 검증 규칙 형식(SVRF)은 설계 규칙 검사(DRC), 레이아웃 대 회로도(LVS) 및 광학 근접 보정(OPC)과 같은 반도체 애플리케이션에 필수적이지만, 노드의 발전으로 인해 기존 SVRF 개발이 비효율적으로 되는 복잡한 설계 규칙이 생성되면서 문제에 직면하고 있습니다.

## 31. VTS-Guided AI Interaction Workflow for Business Insights
- **Authors:** Sun Ding, Ude Enebeli, Atilhan (Ati)Manay, Ryan Pua, Kamal Kotak
- **URL:** https://arxiv.org/abs/2507.00347
- **요약 (영문):** VTS-AI works in three tiers (micro, meso, macro) so agents can extract business insights from unstructured text, tables, and images at scale . it tags issues, links them to source .
- **요약 (한글):** VTS-AI는 세 가지 계층(마이크로, 메조, 매크로)으로 작동하므로 상담원이 비정형 텍스트, 표 및 이미지에서 대규모로 비즈니스 인사이트를 추출할 수 있으며, 이슈에 태그를 지정하고 소스에 연결합니다.
