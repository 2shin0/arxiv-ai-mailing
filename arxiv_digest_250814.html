<strong>arXiv cs.AI 논문 요약 Digest - 2025-08-14</strong><br><br>
<h3>🔍 LLM 관련 논문</h3>
<strong>1. Mathematical Computation and Reasoning Errors by Large Language Models</strong>
- Authors: Liang Zhang, Edith Aurora Graf
- URL: <a href='https://arxiv.org/abs/2508.09932'>https://arxiv.org/abs/2508.09932</a>
- 요약 (영문): Large Language Models (LLMs) are increasingly used in AI-driven instruction and assessment . the ability of LLMs to generate accurate answers and detailed solutions for math problem-solving tasks is foundational for ensuring reliable and precise feedback .
- 요약 (한글): 대규모 언어 모델(LLM)은 AI 기반 교육 및 평가에 점점 더 많이 사용되고 있습니다. 수학 문제 해결 과제에 대한 정확한 답변과 상세한 솔루션을 생성하는 LLM의 능력은 신뢰할 수 있고 정확한 피드백을 보장하기 위한 기본입니다.<br><br>
<strong>2. RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA</strong>
- Authors: Bhavik Agarwal, Hemant Sunil Jomraj, Simone Kaplunov, Jack Krolick, Viktoria Rojkova
- URL: <a href='https://arxiv.org/abs/2508.09893'>https://arxiv.org/abs/2508.09893</a>
- 요약 (영문): Regulatory compliance question answering (QA) requires precise, verifiable information . agents build and maintain an ontology-free KG by extracting subject--predicate-object triplets from regulatory documents .
- 요약 (한글): 규정 준수 질문 답변(QA)에는 정확하고 검증 가능한 정보가 필요합니다. 에이전트는 규정 문서에서 주제-술어-객체 삼중 항을 추출하여 온톨로지 없는 KG를 구축하고 유지합니다.<br><br>
<strong>3. AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving</strong>
- Authors: Zhitian Xie, Qintong Wu, Chengyue Yu, Chenyi Zhuang, Jinjie Gu
- URL: <a href='https://arxiv.org/abs/2508.09889'>https://arxiv.org/abs/2508.09889</a>
- 요약 (영문): the rapid advancement of large language models (LLMs) has empowered agents to leverage diverse external tools for solving complex real-world problems . these challenges underscore the necessity for enhanced stability in agent-based systems .
- 요약 (한글): 대규모 언어 모델(LLM)의 급속한 발전으로 에이전트는 복잡한 실제 문제를 해결하기 위해 다양한 외부 도구를 활용할 수 있게 되었습니다. 이러한 과제는 에이전트 기반 시스템의 안정성 강화에 대한 필요성을 강조합니다.<br><br>
<strong>4. The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?</strong>
- Authors: Manuel Herrador
- URL: <a href='https://arxiv.org/abs/2508.09762'>https://arxiv.org/abs/2508.09762</a>
- 요약 (영문): current safety benchmarks do not systematically probe a model's decision-making in scenarios where its own instrumental goals conflict with human safety . this represents a critical gap in our ability to measure and measure .
- 요약 (한글): 현재의 안전 벤치마크는 자체 도구적 목표가 인간의 안전과 충돌하는 시나리오에서 모델의 의사 결정을 체계적으로 조사하지 않습니다. 이는 측정 및 측정 능력에 중대한 격차가 있음을 나타냅니다.<br><br>
<strong>5. UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge</strong>
- Authors: Yang Zhang, Cunxiang Wang, Lindong Wu, Wenbo Yu, Yidong Wang, Guangsheng Bao, Jie Tang
- URL: <a href='https://arxiv.org/abs/2508.09724'>https://arxiv.org/abs/2508.09724</a>
- 요약 (영문): bias leads to inconsistent and skewed rankings across different judges . we propose a framework that reduces inter-judge disagreement by dynamically adjusting the Elo ra .
- 요약 (한글): 편견은 다른 심사위원들 사이에서 일관되지 않고 왜곡된 순위로 이어집니다. 저희는 Elo 라를 동적으로 조정하여 심사위원 간 불일치를 줄이는 프레임워크를 제안합니다.<br><br>
<a href="https://2shin0.github.io/arxiv-ai-mailing/LLM/2025-08-14.md" target="_blank" style="display: inline-block; padding: 10px 15px; font-size: 14px; color: #fff; background-color: #007bff; text-decoration: none; border-radius: 5px;">📎 LLM 논문 모두 보기</a><br><br>
<h3>📚 그 외 논문</h3>
<strong>1. Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation</strong>
- Authors: In-Chang Baek, Seoyoung Lee, Sung-Hyun Kim, Geumhwan Hwang, KyungJoong Kim
- URL: <a href='https://arxiv.org/abs/2508.09860'>https://arxiv.org/abs/2508.09860</a>
- 요약 (영문): human-aligned AI is a critical component of co-creativity . it enables models to accurately interpret human intent and generate controllable outputs that align with design goals . existing systems often fall short of exhibiting human-centered behavior .
- 요약 (한글): 인간 중심 AI는 공동 창의성의 핵심 요소로, 모델이 인간의 의도를 정확하게 해석하고 설계 목표에 부합하는 제어 가능한 결과물을 생성할 수 있게 해줍니다. 기존 시스템은 종종 인간 중심의 행동을 보여주지 못합니다.<br><br>
<strong>2. Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete</strong>
- Authors: Avijeet Ghosh, Sujata Ghosh, François Schwarzentruber
- URL: <a href='https://arxiv.org/abs/2508.09784'>https://arxiv.org/abs/2508.09784</a>
- 요약 (영문): Logics for reasoning about knowledge and actions have seen many applications in various domains of multi-agent systems, including epistemic planning . a variant of public announcement logic for thinking about knowledge gets updated based on public observations .
- 요약 (한글): 지식과 행동에 대한 추론을 위한 로직은 인식 계획을 포함하여 다중 에이전트 시스템의 다양한 영역에서 많이 적용되어 왔으며, 지식에 대한 사고를 위한 공개 발표 로직의 변형은 공개 관찰을 기반으로 업데이트됩니다.<br><br>
<strong>3. UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles</strong>
- Authors: Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab
- URL: <a href='https://arxiv.org/abs/2508.09639'>https://arxiv.org/abs/2508.09639</a>
- 요약 (영문): XAI techniques have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics . aleatoric and epistemic reflects irredible uncertainty in predictive models and data .
- 요약 (한글): XAI 기술은 복잡한 앙상블 트리 기반 모델을 해석하는 데 필수적인 도구가 되었으며, 특히 의료 분석과 같이 리스크가 큰 영역에서 예측 모델과 데이터의 불확실성을 반영하는 데 필수적인 도구가 되었습니다.<br><br>
<strong>4. Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation</strong>
- Authors: Junyan Ye, Dongzhi Jiang, Zihao Wang, Leqi Zhu, Zhenghao Hu, Zilong Huang, Jun He, Zhiyuan Yan, Jinghua Yu, Hongsheng Li, Conghui He, Weijia Li
- URL: <a href='https://arxiv.org/abs/2508.09987'>https://arxiv.org/abs/2508.09987</a>
- 요약 (영문): studies have explored distilling image data from GPT-4o to enhance open-source models, achieving notable progress . but a key question remains: why should we use synthetic images?
- 요약 (한글): 오픈 소스 모델을 개선하기 위해 GPT-4o에서 이미지 데이터를 추출하는 연구가 진행되어 괄목할 만한 진전을 이루었지만, 왜 합성 이미지를 사용해야 하는가라는 핵심 질문은 여전히 남아 있습니다.<br><br>
<strong>5. Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model</strong>
- Authors: Zihan Wang, Nina Mahmoudian
- URL: <a href='https://arxiv.org/abs/2508.09971'>https://arxiv.org/abs/2508.09971</a>
- 요약 (영문): vision-driven autonomous river following by unmanned Aerial Vehicles is critical for applications such as rescue, surveillance, and environmental monitoring . we formalize river following as a coverage control problem, yielding diminishing returns as more unique river segments are visited .
- 요약 (한글): 무인 항공기의 비전 기반 자율 하천 추종은 구조, 감시 및 환경 모니터링과 같은 애플리케이션에 매우 중요합니다. 우리는 하천 추종을 커버리지 제어 문제로 공식화하여 더 많은 고유 한 하천 구간을 방문함에 따라 수익이 감소하는 결과를 산출합니다.<br><br>
<a href="https://2shin0.github.io/arxiv-ai-mailing/ALL/2025-08-14.md" target="_blank" style="display: inline-block; padding: 10px 15px; font-size: 14px; color: #fff; background-color: #28a745; text-decoration: none; border-radius: 5px;">📚 전체 논문 보러가기</a>