# [arXiv Digest] 2025-07-08


## 1. When Chain of Thought is Necessary, Language Models Struggle to Evade Monitors
- **Authors:** Scott Emmons, Erik Jenner, David K. Elson, Rif A. Saurous, Senthooran Rajamanoharan, Heng Chen, Irhum Shafkat, Rohin Shah
- **URL:** https://arxiv.org/abs/2507.05246
- **요약 (영문):** chain-of-thought (CoT) monitoring is an appealing AI safety defense . recent work on "unfaithfulness" has cast doubt on its reliability .
- **요약 (한글):** 생각의 사슬(CoT) 모니터링은 매력적인 AI 안전 방어 수단이지만, 최근 '불성실성'에 대한 연구로 인해 그 신뢰성에 의문이 제기되고 있습니다.

## 2. Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent Collaboration
- **Authors:** Benjamin Li, Shuyang Shi, Lucia Romero, Huao Li, Yaqi Xie, Woojun Kim, Stefanos Nikolaidis, Michael Lewis, Katia Sycara, Simon Stepputtis
- **URL:** https://arxiv.org/abs/2507.05244
- **요약 (영문):** TALENTS is a strategy-conditioned cooperator framework . it learns to represent, categorize, and categorate human partners in real time . this is particularly challenging in tasks with time pressure .
- **요약 (한글):** TALENTS는 전략 조건부 협력자 프레임워크로, 실시간으로 인간 파트너를 표현하고 분류하고 분류하는 방법을 학습합니다. 이는 시간 압박이 있는 작업에서 특히 어렵습니다.

## 3. SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?
- **Authors:** Jingyi Chai, Shuo Tang, Rui Ye, Yuwen Du, Xinyu Zhu, Mengcheng Zhou, Yanfeng Wang, Weinan E, Siheng Chen
- **URL:** https://arxiv.org/abs/2507.05241
- **요약 (영문):** the rapid advancements of AI agents have ignited the long-held ambition of leveraging them to accelerate scientific discovery . humanity's last exam (HLE) provides an exceptionally challenging touchstone for evaluating scientific AI agents .
- **요약 (한글):** 인공지능 에이전트의 급속한 발전은 과학적 발견을 가속화하기 위해 인공지능을 활용하려는 오랜 야망에 불을 붙였습니다. 인류의 마지막 시험(HLE)은 과학적 인공지능 에이전트를 평가하는 데 매우 어려운 시금석이 될 것입니다.

## 4. MedGemma Technical Report
- **Authors:** Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil, Cían Hughes, Charles Lau, Justin Chen, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Stefanie Anna Baby, Susanna Maria Baby, Jeremy Lai, Samuel Schmidgall, Lu Yang, Kejia Chen, Per Bjornsson, Shashir Reddy, Ryan Brush, Kenneth Philbrick, Howard Hu, Howard Yang, Richa Tiwari, Sunny Jansen, Preeti Singh, Yun Liu, Shekoofeh Azizi, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Riviere, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean-bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Elena Buchatskaya, Jean-Baptiste Alayrac, Dmitry (Dima)Lepikhin, Vlad Feinberg, Sebastian Borgeaud, Alek Andreev, Cassidy Hardin, Robert Dadashi, Léonard Hussenot, Armand Joulin, Olivier Bachem, Yossi Matias, Katherine Chou, Avinatan Hassidim, Kavi Goel, Clement Farabet, Joelle Barral, Tris Warkentin, Jonathon Shlens, David Fleet, Victor Cotruta, Omar Sanseviero, Gus Martins, Phoebe Kirk, Anand Rao, Shravya Shetty, David F. Steiner, Can Kirmizibayrak, Rory Pilgrim, Daniel Golden, Lin Yang
- **URL:** https://arxiv.org/abs/2507.05201
- **요약 (영문):** foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications . a collection of medical vision-language foundation models based on Gemma 3 4B and 27B .
- **요약 (한글):** 의료 작업에서 우수한 성능을 발휘하고 작업별 튜닝 데이터가 적게 필요한 파운데이션 모델은 의료 AI 애플리케이션 개발을 가속화하는 데 매우 중요합니다. Gemma 3 4B 및 27B 기반의 의료 비전 언어 파운데이션 모델 모음입니다.

## 5. GIST: Cross-Domain Click-Through Rate Prediction via Guided Content-Behavior Distillation
- **Authors:** Wei Xu, Haoran Li, Baoyuan Ou, Lai Xu, Yingjie Qin, Ruilong Su, Ruiwen Xu
- **URL:** https://arxiv.org/abs/2507.05142
- **요약 (영문):** cross-domain Click-Through Rate prediction aims to tackle data sparsity and cold start problems in online advertising systems . most existing methods rely on overlapping users to facilitate this transfer . but in real-world industrial settings, joint training struggles to learn optimal representations with different drs .
- **요약 (한글):** 크로스 도메인 클릭률 예측은 온라인 광고 시스템의 데이터 희소성과 콜드 스타트 문제를 해결하는 것을 목표로 합니다. 대부분의 기존 방법은 중복 사용자에 의존하여 이러한 전송을 촉진하지만 실제 산업 환경에서 공동 학습은 다양한 DR을 통해 최적의 표현을 학습하는 데 어려움을 겪습니다.

## 6. Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift
- **Authors:** Shixuan Liu, Yue He, Yunfei Wang, Hao Zou, Haoxiang Cheng, Wenjing Yang, Peng Cui, Zhong Liu
- **URL:** https://arxiv.org/abs/2507.05110
- **요약 (영문):** KG reasoning is a critical research area focused on inferring missing knowledge . the assumption can easily be violated due to unknown sample selection bias during training or agnostic distribution shifts during testing .
- **요약 (한글):** KG 추론은 누락된 지식을 추론하는 데 중점을 둔 중요한 연구 영역으로, 훈련 중 알 수 없는 표본 선택 편향이나 테스트 중 불가지론적 분포 변화로 인해 가정이 쉽게 위반될 수 있습니다.

## 7. How Rules Represent Causal Knowledge: Causal Modeling with Abductive Logic Programs
- **Authors:** Kilian Rückschloß, Felix Weitkämper
- **URL:** https://arxiv.org/abs/2507.05088
- **요약 (영문):** this paper extends Pearl's approach to causality and interventions to the setting of stratified abductive logic programs . it provides a translatioo of causal knowledge by building on philosophical foundations .
- **요약 (한글):** 이 논문은 인과관계와 개입에 대한 펄의 접근 방식을 계층화된 납치 논리 프로그램의 설정으로 확장합니다. 철학적 토대를 구축하여 인과적 지식의 번역을 제공합니다.

## 8. When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning
- **Authors:** Maxence Boels, Harry Robertshaw, Alejandro Granados, Prokar Dasgupta, Sebastien Ourselin
- **URL:** https://arxiv.org/abs/2507.05011
- **요약 (영문):** teleoperated robotic surgery provides natural expert demonstrations for imitation learning (IL) reinforcement learning (RL) could potentially discover superior strategies through exploration . the first comprehensive comparison of IL versus RL .
- **요약 (한글):** 원격 수술 로봇 수술은 모방 학습(IL)을 위한 자연스러운 전문가 시연을 제공합니다 강화 학습(RL)은 탐색을 통해 잠재적으로 우수한 전략을 발견할 수 있습니다 IL과 RL의 첫 번째 포괄적 비교 .

## 9. Supported Abstract Argumentation for Case-Based Reasoning
- **Authors:** Adam Gould, Gabriel de Olim Gaul, Francesca Toni
- **URL:** https://arxiv.org/abs/2507.04994
- **요약 (영문):** supported Abstract argumentation for case-based reasoning (sAA-CBR) is a binary classification model in which past cases engage in debates by arguing in favour of their labelling and attacking or supporting those with opposing or agreeing labels.
- **요약 (한글):** 지원되는 사례 기반 추론을 위한 추상적 논증(sAA-CBR)은 과거 사례들이 자신의 라벨에 찬성하고 반대 또는 동의 라벨을 가진 사례들을 공격하거나 지지함으로써 토론에 참여하는 이분법적 분류 모델입니다.

## 10. MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction
- **Authors:** Kaleem Ullah Qasim, Jiashu Zhang
- **URL:** https://arxiv.org/abs/2507.04893
- **요약 (영문):** accident severity prediction plays a critical role in transportation safety systems but is a persistently difficult task due to incomplete data, strong feature dependencies and severe class imbalance . existing methods often rely on monolithic models or black box prompting, which struggle to scale in noisy, real-world settings .
- **요약 (한글):** 사고 심각도 예측은 교통 안전 시스템에서 중요한 역할을 하지만 불완전한 데이터, 강력한 기능 종속성, 심각한 등급 불균형으로 인해 지속적으로 어려운 작업입니다. 기존 방법은 종종 모놀리식 모델이나 블랙박스 프롬프트에 의존하는데, 이는 잡음이 많은 실제 환경에서 확장하기 어렵습니다.

## 11. DoPI: Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine
- **Authors:** Zewen Sun, Ruoxiang Huang, Jiahe Feng, Rundong Kong, Yuqian Wang, Hengyu Liu, Ziqi Gong, Yuyuan Qin, Yingxue Wang, Yu Wang
- **URL:** https://arxiv.org/abs/2507.04877
- **요약 (영문):** current large language models exhibit notable limitations in medical applications, particularly in conducting effective multi-turn dialogues and proactive questioning . these shortcomings hinder practical application and effectiveness in simulating real-world diagnostic scenarios .
- **요약 (한글):** 현재의 대규모 언어 모델은 의료 애플리케이션, 특히 효과적인 멀티턴 대화 및 사전 질문 수행에 있어 현저한 한계를 보입니다. 이러한 단점은 실제 진단 시나리오를 시뮬레이션할 때 실제 적용과 효과를 저해합니다.

## 12. Application and Evaluation of Large Language Models for Forecasting the Impact of Traffic Incidents
- **Authors:** George Jagadeesh, Srikrishna Iyer, Michal Polanowski, Kai Xin Thia
- **URL:** https://arxiv.org/abs/2507.04803
- **요약 (영문):** this study examines the feasibility of applying large language models for forecasting the impact of traffic incidents on the traffic flow . the use of LLMs has several advantages over existing machine learning-based solutions such as not requiring a large training dataset and the ability to utilize incident logs .
- **요약 (한글):** 이 연구는 교통 사고가 교통 흐름에 미치는 영향을 예측하기 위한 대규모 언어 모델 적용의 타당성을 검토합니다. LLM을 사용하면 대규모 학습 데이터 세트가 필요하지 않고 사고 로그를 활용할 수 있는 등 기존 머신 러닝 기반 솔루션에 비해 몇 가지 장점이 있습니다.

## 13. FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System
- **Authors:** Toan Nguyen, Tri Le, Quang Nguyen, Anh Nguyen
- **URL:** https://arxiv.org/abs/2507.04770
- **요약 (영문):** we propose a multi-agent system for automatic furniture decoration . given a human prompt and a household furniture item such as a working desk or a TV stand, our system suggests automating the decoration process.
- **요약 (한글):** 우리는 자동 가구 장식을 위한 다중 에이전트 시스템을 제안합니다. 사람의 프롬프트와 작업용 책상이나 TV 스탠드와 같은 가정용 가구 품목이 주어지면 우리 시스템은 장식 프로세스를 자동화할 것을 제안합니다.

## 14. LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction
- **Authors:** Sungmin Lee, Minju Kang, Joonhee Lee, Seungyong Lee, Dongju Kim, Jingi Hong, Jun Shin, Pei Zhang, JeongGil Ko
- **URL:** https://arxiv.org/abs/2507.04748
- **요약 (영문):** QA interfaces powered by large language models (LLMs) present a promising direction for improving interactivity with HVAC systems . enabling accurate, real-time, and context-aware interactions introduces unique challenges, including the integration of frequently updated sensor data .
- **요약 (한글):** 대규모 언어 모델(LLM)로 구동되는 QA 인터페이스는 HVAC 시스템과의 상호 작용을 개선하기 위한 유망한 방향을 제시합니다. 정확한 실시간 상황 인식 상호 작용을 구현하려면 자주 업데이트되는 센서 데이터의 통합을 비롯한 고유한 과제가 발생합니다.

## 15. Activation Steering for Chain-of-Thought Compression
- **Authors:** Seyedarmin Azizi, Erfan Baghaei Potraghloo, Massoud Pedram
- **URL:** https://arxiv.org/abs/2507.04742
- **요약 (영문):** large language models excel at complex reasoning when they include intermediate steps . verbose, English-heavy CoTs and concise, math-centric coTs occupy distinct regions in the model's residual-stream activation space .
- **요약 (한글):** 대규모 언어 모델은 중간 단계를 포함할 때 복잡한 추론에 탁월합니다. 장황한 영어 중심의 CoT와 간결하고 수학 중심적인 CoT는 모델의 잔류 스트림 활성화 공간에서 서로 다른 영역을 차지합니다.

## 16. ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning
- **Authors:** Zhirong Chen, Kaiyan Chang, Zhuolin Li, Xinyang He, Chujie Chen, Cangyuan Li, Mengdi Wang, Haobo Xu, Yinhe Han, Ying Wang
- **URL:** https://arxiv.org/abs/2507.04736
- **요약 (영문):** large language models (LLMs) show significant potential for automating RTL code generation . but current approaches face a critical challenge: they can not simultaneously optimize for functional correctness and hardware quality . post-processing techniques that attempt to improve PP can improve performance .
- **요약 (한글):** 대규모 언어 모델(LLM)은 RTL 코드 생성 자동화에 상당한 잠재력을 보이지만 현재의 접근 방식은 기능적 정확성과 하드웨어 품질을 동시에 최적화할 수 없다는 중요한 과제에 직면해 있습니다. PP를 개선하려는 후처리 기술은 성능을 향상시킬 수 있습니다.

## 17. LumiCRS: Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Movie Recommendation
- **Authors:** Jinzhi Wang, Bin Li, Qingke Peng, Haozhou Li, Zeyuan Zeng, Ruimeng Li, Biyi Zhou
- **URL:** https://arxiv.org/abs/2507.04722
- **요약 (영문):** only 10% of head movies account for nearly half of all mentions . about 70% of tail movies receive merely 26% of the attention . this imbalance gives rise to three critical challenges .
- **요약 (한글):** 헤드 무비의 10%만이 전체 언급의 거의 절반을 차지합니다. 꼬리 무비의 약 70%가 26%의 관심만을 받습니다. 이러한 불균형은 세 가지 중요한 과제를 야기합니다.

## 18. Advocate for Complete Benchmarks for Formal Reasoning with Formal/Informal Statements and Formal/Informal Proofs
- **Authors:** Roozbeh Yousefzadeh, Xuenan Cao
- **URL:** https://arxiv.org/abs/2507.04719
- **요약 (영문):** this position paper provides a critical but constructive discussion of current practices in benchmarking and evaluative practices . we identify practices that create barriers to contributing to this field and suggest ways to remove them .
- **요약 (한글):** 이 입장문은 벤치마킹 및 평가 관행의 현재 관행에 대해 비판적이면서도 건설적인 논의를 제공하며, 이 분야에 기여하는 데 장애가 되는 관행을 파악하고 이를 제거할 수 있는 방법을 제안합니다.

## 19. Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message
- **Authors:** Wei Duan, Li Qian
- **URL:** https://arxiv.org/abs/2507.04673
- **요약 (영문):** the rise of conversational interfaces has greatly enhanced usability . this reliance introduces an unexplored attack surface . a malicious payload is injected into a model-attributed message .
- **요약 (한글):** 대화형 인터페이스의 등장으로 사용성이 크게 향상되었습니다. 이러한 의존성은 미개척 공격 표면을 도입합니다. 모델 어트리뷰션 메시지에 악성 페이로드가 삽입됩니다.

## 20. Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?
- **Authors:** Yun Qu, Qi Cheems Wang, Yixiu Mao, Vincent Tao Hu, Xiangyang Ji
- **URL:** https://arxiv.org/abs/2507.04632
- **요약 (영문):** recent advances have witnessed the effectiveness of reinforcement learning (RL) finetuning in enhancing the reasoning capabilities of large language models (LLMs) the optimization process often requires numerous iterations to achieve satisfactory performance .
- **요약 (한글):** 최근의 발전으로 대규모 언어 모델(LLM)의 추론 능력을 향상시키는 데 있어 강화 학습(RL) 미세 조정의 효과가 입증되었습니다. 최적화 프로세스에는 만족스러운 성능을 달성하기 위해 수많은 반복이 필요한 경우가 많습니다.

## 21. DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification
- **Authors:** Zhipeng Liu, Peibo Duan, Binwu Wang, Xuan Tang, Qi Chu, Changsheng Zhang, Yongsheng Huang, Bin Zhang
- **URL:** https://arxiv.org/abs/2507.04600
- **요약 (영문):** real-world time series typically exhibit complex temporal variations . existing analysis-based time series prediction methods fail to eliminate redundant scale-shared features across multi-scale time series . model over- or under-focusing on temporal patterns .
- **요약 (한글):** 실제 시계열은 일반적으로 복잡한 시간적 변화를 보입니다. 기존의 분석 기반 시계열 예측 방법은 다중 규모 시계열에서 중복된 규모 공유 특징을 제거하지 못합니다. 시간적 패턴에 과도하게 또는 과소하게 초점을 맞추는 모델을 만듭니다.

## 22. Exploring Core and Periphery Precepts in Biological and Artificial Intelligence: An Outcome-Based Perspective
- **Authors:** Niloofar Shadab, Tyler Cody, Alejandro Salado, Taylan G. Topcu, Mohammad Shadab, Peter Beling
- **URL:** https://arxiv.org/abs/2507.04594
- **요약 (영문):** engineering methodologies revolve around established principles of decomposition and recomposition . these principles involve partitioning inputs and outputs at the component level . this view does not transfer well to intelligent systems, particularly when addressing scaling of intelligence as a system property .
- **요약 (한글):** 엔지니어링 방법론은 분해와 재구성의 확립된 원칙을 중심으로 진행되며, 이러한 원칙에는 구성 요소 수준에서 입력과 출력을 분할하는 것이 포함됩니다. 이러한 관점은 특히 시스템 속성으로서 지능의 확장을 다룰 때 지능형 시스템에는 잘 적용되지 않습니다.

## 23. Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions
- **Authors:** Yuanzhe Hu, Yu Wang, Julian McAuley
- **URL:** https://arxiv.org/abs/2507.05257
- **요약 (영문):** benchmarks for LLM agents focus on evaluating reasoning, planning, and execution capabilities . another critical component-memory, encompassing how agents memorize, update, and retrieve long-term information, is under-evaluated .
- **요약 (한글):** LLM 에이전트에 대한 벤치마크는 추론, 계획 및 실행 능력을 평가하는 데 중점을 두고 있습니다. 또 다른 중요한 요소인 에이전트가 장기 정보를 암기, 업데이트 및 검색하는 방법을 포괄하는 메모리는 저평가되어 있습니다.

## 24. From Marginal to Joint Predictions: Evaluating Scene-Consistent Trajectory Prediction Approaches for Automated Driving
- **Authors:** Fabian Konstantinidis, Ariel Dallari Guerreiro, Raphael Trumpp, Moritz Sackmann, Ulrich Hofmann, Marco Caccamo, Christoph Stiller
- **URL:** https://arxiv.org/abs/2507.05254
- **요약 (영문):** apg predicts traffic participants' future trajectories in dynamic environments . compared to previous models, joint prediction models explicitly account for interactions between agents .
- **요약 (한글):** APG는 동적 환경에서 트래픽 참가자의 미래 궤적을 예측합니다. 이전 모델에 비해 공동 예측 모델은 에이전트 간의 상호 작용을 명시적으로 설명합니다.

## 25. Action Space Reduction Strategies for Reinforcement Learning in Autonomous Driving
- **Authors:** Elahe Delavari, Feeza Khan Khanzada, Jaerock Kwon
- **URL:** https://arxiv.org/abs/2507.05251
- **요약 (영문):** RL allows agents to learn control policies through interaction with environments . large and high-dimensional action spaces often used to support fine-grained control can impede training efficiency and increase exploration costs .
- **요약 (한글):** 에이전트는 환경과의 상호작용을 통해 제어 정책을 학습할 수 있습니다. 세분화된 제어를 지원하는 데 자주 사용되는 크고 고차원적인 작업 공간은 훈련 효율성을 저해하고 탐색 비용을 증가시킬 수 있습니다.

## 26. CTA: Cross-Task Alignment for Better Test Time Training
- **Authors:** Samuel Barbeau, Pedram Fekri, David Osowiechi, Ali Bahri, Moslem YazdanpanahMasih Aminbeidokhti, Christian Desrosiers
- **URL:** https://arxiv.org/abs/2507.05221
- **요약 (영문):** test-time training has emerged as an effective method to enhance model robustness by incorporating an auxiliary unsupervised task during training and leveraging it for model updates at test time .
- **요약 (한글):** 테스트 시간 훈련은 훈련 중에 보조적인 비지도 작업을 통합하고 테스트 시간에 모델 업데이트에 활용함으로써 모델 견고성을 향상시키는 효과적인 방법으로 부상했습니다.

## 27. All in One: Visual-Description-Guided Unified Point Cloud Segmentation
- **Authors:** Zongyan Han, Mohamed El Amine Boudjoghra, Jiahua Dong, Jinhong Wang, Rao Muhammad Anwer
- **URL:** https://arxiv.org/abs/2507.05211
- **요약 (영문):** unified segmentation of 3D point clouds is crucial for scene understanding, but is hindered by its sparse structure, limited annotations, and the challenge of distinguishing fine-grained objects in complex environments . to address these challenges, we propose VDG-Uni3DSeg, a novel framework .
- **요약 (한글):** 3D 포인트 클라우드의 통합된 분할은 장면 이해에 매우 중요하지만, 희박한 구조와 제한된 주석, 복잡한 환경에서 세분화된 오브젝트를 구별하는 데 어려움을 겪습니다. 이러한 문제를 해결하기 위해 유니티는 새로운 프레임워크인 VDG-Uni3DSeg를 제안합니다.

## 28. EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling
- **Authors:** Boyuan Wang, Xinpan Meng, Xiaofeng Wang, Zheng Zhu, Angen Ye, Yang Wang, Zhiqin Yang, Chaojun Ni, Guan Huang, Xingang Wang
- **URL:** https://arxiv.org/abs/2507.05198
- **요약 (영문):** the rapid advancement of Embodied AI has led to an increasing demand for large-scale, high-quality real-world data . however, collecting such embodied data remains costly and inefficient .
- **요약 (한글):** 구현형 AI의 급속한 발전으로 대규모의 고품질 실제 데이터에 대한 수요가 증가하고 있지만, 이러한 구현형 데이터를 수집하는 데는 여전히 많은 비용이 들고 비효율적입니다.

## 29. Train-before-Test Harmonizes Language Model Rankings
- **Authors:** Guanhua Zhang, Ricardo Dominguez-Olmedo, Moritz Hardt
- **URL:** https://arxiv.org/abs/2507.05195
- **요약 (영문):** conflicting rankings hamper model selection, clouds comparisons, and adds confusion to growing ecosystem of competing models . a candidate solution to the problem is train on the test task .
- **요약 (한글):** 상충되는 순위는 모델 선택을 방해하고, 비교를 흐리게 하며, 경쟁 모델의 생태계가 성장함에 따라 혼란을 가중시킵니다. 이 문제에 대한 후보 솔루션은 테스트 작업에 대한 훈련입니다.

## 30. Infrastructuring Contestability: A Framework for Community-Defined AI Value Pluralism
- **Authors:** Andreas Mayer
- **URL:** https://arxiv.org/abs/2507.05187
- **요약 (영문):** the proliferation of AI-driven systems presents a fundamental challenge to human-computer interaction and computer-supported cooperative work . current approaches to value alignment lack the mechanisms for meaningful contestability . this leaves users unable to challenge or shape the values embedded in the systems that govern their digital lives .
- **요약 (한글):** AI 기반 시스템의 확산은 인간과 컴퓨터의 상호 작용 및 컴퓨터 지원 협력 작업에 근본적인 도전을 제시합니다. 가치 정렬에 대한 현재의 접근 방식에는 의미 있는 경쟁 가능성을 위한 메커니즘이 부족합니다. 이로 인해 사용자는 디지털 생활을 지배하는 시스템에 내재된 가치에 도전하거나 이를 형성할 수 없습니다.

## 31. CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale
- **Authors:** Jonathan Hyun, Nicholas R Waytowich, Boyuan Chen
- **URL:** https://arxiv.org/abs/2507.05178
- **요약 (영문):** despite rapid progress in large language model (LLM)-based multi-agent systems, current benchmarks fall short in evaluating their scalability, robustness, and coordination capabilities . existing environments typically focus on small-scale, fully observable, or low-complexity domains .
- **요약 (한글):** 대규모 언어 모델(LLM) 기반 다중 에이전트 시스템의 빠른 발전에도 불구하고 현재 벤치마크는 확장성, 견고성 및 조정 기능을 평가하는 데 부족합니다. 기존 환경은 일반적으로 소규모, 완전히 관찰 가능하거나 복잡성이 낮은 도메인에 초점을 맞추고 있습니다.

## 32. OpenS2S: Advancing Open-Source End-to-End Empathetic Large Speech Language Model
- **Authors:** Chen Wang, Tianyu Peng, Wen Yang, Yinan Bai, Guangfu Wang, Jun Lin, Lanpeng Jia, Lingxiang Wu, Jinqiao Wang, Chengqing Zong, Jiajun Zhang
- **URL:** https://arxiv.org/abs/2507.05177
- **요약 (영문):** the most powerful empathetic LSLMs are closed off, leaving the crucial details about the architecture, data and development opaque to researchers . openS2S is a fully open-source, transparent and transparent .
- **요약 (한글):** 가장 강력한 공감형 LSLM은 폐쇄적이어서 아키텍처, 데이터 및 개발에 대한 중요한 세부 사항을 연구자에게 불투명하게 남겨두고 있습니다. openS2S는 완전 오픈 소스이며 투명하고 투명한 .

## 33. Critiques of World Models
- **Authors:** Eric Xing, Mingkai Deng, Jinyu Hou, Zhiting Hu
- **URL:** https://arxiv.org/abs/2507.05169
- **요약 (영문):** there has been much debate on what a world model really is, how to build it, and how to evaluate it . in this essay, we draw inspiration from the concept of "hypnotic"
- **요약 (한글):** 세계 모델이 실제로 무엇인지, 어떻게 구축하는지, 어떻게 평가하는지에 대해 많은 논쟁이 있었습니다. 이 에세이에서는 "최면"이라는 개념에서 영감을 얻었습니다.

## 34. LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains
- **Authors:** Nicholas Chivaran, Jianbing Ni
- **URL:** https://arxiv.org/abs/2507.05162
- **요약 (영문):** current state-of-the-art AIGI detection methods typically rely on large, deep neural architectures . this creates significant computational barriers to real-time, large-scale deployment on social media platforms .
- **요약 (한글):** 현재의 최신 AIGI 탐지 방법은 일반적으로 대규모의 심층 신경 아키텍처에 의존하기 때문에 소셜 미디어 플랫폼에 실시간으로 대규모로 배포하는 데 상당한 계산상의 장벽이 있습니다.

## 35. AI Generated Text Detection Using Instruction Fine-tuned Large Language and Transformer-Based Models
- **Authors:** Chinnappa Guggilla, Budhaditya Roy, Trupti Ramdas Chavan, Abdul Rahman, Edward Bowen
- **URL:** https://arxiv.org/abs/2507.05157
- **요약 (영문):** Large Language Models (LLMs) adapt to various styles and genres . they produce content that is both grammatically correct and semantically meaningful . recently, they have been misused to create highly realistic phishing emails, spread fake news, generate code to automate cyber crime .
- **요약 (한글):** LLM(대규모 언어 모델)은 다양한 스타일과 장르에 적응하며 문법적으로 정확하고 의미적으로 의미 있는 콘텐츠를 생성하며 최근에는 매우 사실적인 피싱 이메일 생성, 가짜 뉴스 확산, 사이버 범죄 자동화를 위한 코드 생성에 악용되고 있습니다.

## 36. Effects of Unplanned Incoming Flights on Airport Relief Processes after a Major Natural Disaster
- **Authors:** Luka Van de Sype, Matthieu Vert, Alexei Sharpanskykh, Seyed Sahand Mohammadi Ziabari
- **URL:** https://arxiv.org/abs/2507.05150
- **요약 (영문):** airports are important hubs where relief aid arrives and people need to be evacuated . the airport often forms a bottleneck due to the sudden need for increased capacity .
- **요약 (한글):** 공항은 구호품이 도착하고 사람들이 대피해야 하는 중요한 허브입니다. 공항은 갑작스러운 수용 인원 증가로 인해 병목 현상이 발생하는 경우가 많습니다.

## 37. OGF: An Online Gradient Flow Method for Optimizing the Statistical Steady-State Time Averages of Unsteady Turbulent Flows
- **Authors:** Tom Hickling, Jonathan F. MacArt, Justin Sirignano, Den Waidmann
- **URL:** https://arxiv.org/abs/2507.05149
- **요약 (영문):** engineering quantities of interest typically take the form of time-average statistics such as $ frac1t int_0t f . optimization over $F(x; theta)$ has many engineering applications including geometric optimizationa .
- **요약 (한글):** 공학적으로 관심 있는 수량은 일반적으로 $ frac1t int_0t f 와 같은 시간 평균 통계의 형태를 취합니다. $F(x; 세타)$ 에 대한 최적화는 기하학적 최적화를 포함한 많은 공학 응용 분야가 있습니다a .

## 38. Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization
- **Authors:** Jaewook Lee, Alexander Scarlatos, Andrew Lan
- **URL:** https://arxiv.org/abs/2507.05137
- **요약 (영문):** Japanese combines syllabaries like hiragana with kanji, which are logographic characters of Chinese origin . keywords mnemonics are a common strategy to aid memorization .
- **요약 (한글):** 일본어는 히라가나와 같은 음절과 한자, 즉 한자에서 유래한 문자를 결합한 언어입니다. 키워드 니모닉은 암기를 돕기 위한 일반적인 전략입니다.

## 39. An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques
- **Authors:** Walid Mohamed Aly, Taysir Hassan A. Soliman, Amr Mohamed AbdelAziz
- **URL:** https://arxiv.org/abs/2507.05123
- **요약 (영문):** Large Language Models (LLMs) continue to advance natural language processing . their ability to generate human-like text has not been comprehensively evaluated .
- **요약 (한글):** 대규모 언어 모델(LLM)은 자연어 처리를 지속적으로 발전시키고 있지만, 인간과 유사한 텍스트를 생성하는 능력은 종합적으로 평가되지 않았습니다.

## 40. LVM4CSI: Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks
- **Authors:** Jiajia Guo, Peiwen Jiang, Chao-Kai Wen, Shi Jin, Jun Zhang
- **URL:** https://arxiv.org/abs/2507.05121
- **요약 (영문):** Accurate channel state information (CSI) is critical to wireless communication systems . existing methods depend on task-specific neural networks (NNs) that require expert-driven design and large training datasets .
- **요약 (한글):** 정확한 채널 상태 정보(CSI)는 무선 통신 시스템에 매우 중요하며, 기존 방법은 전문가 중심의 설계와 대규모 학습 데이터 세트가 필요한 작업별 신경망(NN)에 의존합니다.

## 41. VerifyLLM: LLM-Based Pre-Execution Task Plan Verification for Robots
- **Authors:** Danil S. Grigorev, Alexey K. Kovalev, Aleksandr I. Panov
- **URL:** https://arxiv.org/abs/2507.05118
- **요약 (영문):** we propose an architecture for automatically verifying high-level task plans before their execution in simulators or real-world environments . the approach consists of two key steps: first, the conversion of natu .
- **요약 (한글):** 우리는 시뮬레이터 또는 실제 환경에서 실행하기 전에 높은 수준의 작업 계획을 자동으로 검증하는 아키텍처를 제안합니다. 이 접근 방식은 두 가지 주요 단계로 구성됩니다: 첫째, natu의 변환 .

## 42. Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration
- **Authors:** Yuyi Zhang, Peirong Zhang, Zhenhua Yang, Pengyu Yan, Yongxin Shi, Pengwei Liu, Fengjun Guo, Lianwen Jin
- **URL:** https://arxiv.org/abs/2507.05108
- **요약 (영문):** historical documents have undergone significant degradation over time through tears, water erosion, and oxidation . existing methods focus on single modality or limited-size restoration, failing to meet practical needs .
- **요약 (한글):** 역사적 문서는 시간이 지남에 따라 찢어짐, 침식, 산화 등으로 인해 상당한 열화를 겪었습니다. 기존 방식은 단일 양식 또는 제한된 크기의 복원에 초점을 맞추기 때문에 실질적인 요구를 충족시키지 못했습니다.

## 43. PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs
- **Authors:** Xinzhe Zheng, Hao Du, Fanding Xu, Jinzhe Li, Zhiyuan Liu, Wenkang Wang, Tao Chen, Wanli Ouyang, Stan Z. Li, Yan Lu, Nanqing Dong, Yang Zhang
- **URL:** https://arxiv.org/abs/2507.05101
- **요약 (영문):** existing benchmarks focus on isolated pairwise evaluations . a model's capability to reconstruct biologically meaningful PPI networks is crucial .
- **요약 (한글):** 기존 벤치마크는 고립된 쌍별 평가에 초점을 맞추고 있습니다. 생물학적으로 의미 있는 PPI 네트워크를 재구성하는 모델의 역량이 중요합니다.

## 44. Beyond Features: How Dataset Design Influences Multi-Agent Trajectory Prediction Performance
- **Authors:** Tobias Demmler, Jakob Häringer, Andreas Tamke, Thao Dang, Alexander Hegai, Lars Mikelsons
- **URL:** https://arxiv.org/abs/2507.05098
- **요약 (영문):** this work systematically examines how feature selection, cross-dataset transfer, and geographic diversity influence trajectory prediction accuracy in multi-agent settings .
- **요약 (한글):** 이 연구는 특징 선택, 데이터 세트 간 전송 및 지리적 다양성이 다중 에이전트 설정에서 궤적 예측 정확도에 미치는 영향을 체계적으로 조사합니다.

## 45. The Hidden Threat in Plain Text: Attacking RAG Data Loaders
- **Authors:** Alberto Castagnaro, Umberto Salviati, Mauro Conti, Luca Pajola, Simeone Pizzi
- **URL:** https://arxiv.org/abs/2507.05093
- **요약 (영문):** large language models (LLMs) have transformed human-machine interaction since chatGPT's 2022 debut . reliance on ingesting external documents introduces new vulnerabilities . this paper exposes a critical security gap at the data loading stage .
- **요약 (한글):** 대규모 언어 모델(LLM)은 채팅GPT의 2022년 데뷔 이후 인간과 기계의 상호작용을 변화시켰습니다. 외부 문서 수집에 의존하면 새로운 취약점이 발생합니다. 이 백서에서는 데이터 로드 단계에서 중요한 보안 격차를 노출합니다.

## 46. Sequential Attention-based Sampling for Histopathological Analysis
- **Authors:** Tarun G, Naman Malpani, Gugan Thoppe, Sridharan Devarajan
- **URL:** https://arxiv.org/abs/2507.05077
- **요약 (영문):** whole-slide images are often acquired at gigapixel sizes . diagnostic labels are available only at the slide-level . regions with diagnostic information typically occupy only a small fraction of the WSI .
- **요약 (한글):** 전체 슬라이드 이미지는 종종 기가픽셀 크기로 획득됩니다. 진단 라벨은 슬라이드 수준에서만 사용할 수 있습니다. 진단 정보가 있는 영역은 일반적으로 WSI의 작은 부분만 차지합니다.

## 47. ICAS: Detecting Training Data from Autoregressive Image Generative Models
- **Authors:** Hongyao Yu, Yixiang Qiu, Yiheng Yang, Hao Fang, Tianqu Zhuang, Jiaxin Hong, Bin Chen, Hao Wu, Shu-Tao Xia
- **URL:** https://arxiv.org/abs/2507.05068
- **요약 (영문):** training data detection has emerged as a critical task for identifying unauthorized data usage in model training . we conduct thames of thursday to better understand the vulnerability of auto-regression models to such detection .
- **요약 (한글):** 훈련 데이터 탐지는 모델 훈련에서 무단 데이터 사용을 식별하는 데 중요한 작업으로 부상했습니다. 이러한 탐지에 대한 자동 회귀 모델의 취약성을 더 잘 이해하기 위해 목요일의 템즈를 실시합니다.

## 48. Replacing thinking with tool usage enables reasoning in small language models
- **Authors:** Corrado Rainone, Tim Bakker, Roland Memisevic
- **URL:** https://arxiv.org/abs/2507.05065
- **요약 (영문):** a combination of supervised fine-tuning and Reinforcement Learning with Verifiable Rewards is used for training Large Language Models to expend extra compute during inference . in this paper, we propose to format these tokens as a multi-turn inte .
- **요약 (한글):** 대규모 언어 모델을 훈련하기 위해 감독된 미세 조정과 검증 가능한 보상이 포함된 강화 학습의 조합을 사용하여 추론 중에 추가 컴퓨팅을 소비합니다. 이 논문에서는 이러한 토큰을 멀티 턴 인테로 형식화할 것을 제안합니다.

## 49. INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling
- **Authors:** Xin Dong, Shichao Dong, Jin Wang, Jing Huang, Li Zhou, Zenghui Sun, Lihua Jing, Jingsong Lan, Xiaoyong Zhu, Bo Zheng
- **URL:** https://arxiv.org/abs/2507.05056
- **요약 (영문):** LVLMs may generate responses that appear plausible, but remain inconsistent with the associated visual content . this discrepancy arises from humans' ability to leverage multimodal interaction information .
- **요약 (한글):** LVLM은 그럴듯해 보이지만 관련 시각적 콘텐츠와 일치하지 않는 반응을 생성할 수 있으며, 이러한 불일치는 멀티모달 상호작용 정보를 활용하는 인간의 능력에서 비롯됩니다.

## 50. Perspectives on How Sociology Can Advance Theorizing about Human-Chatbot Interaction and Developing Chatbots for Social Good
- **Authors:** Celeste Campos-Castillo, Xuan Kang, Linnea I. Laestadius
- **URL:** https://arxiv.org/abs/2507.05030
- **요약 (영문):** sociology lags other disciplines in publishing about chatbots . we suggest sociology can advance understanding of human-chatbot interaction and offer four sociological theories .
- **요약 (한글):** 사회학은 챗봇에 관한 출판에서 다른 학문에 비해 뒤쳐져 있습니다. 사회학이 인간과 챗봇의 상호작용에 대한 이해를 증진하고 네 가지 사회학적 이론을 제시할 수 있다고 제안합니다.

## 51. Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision
- **Authors:** Soham Walimbe, Britty Baby, Vinkle Srivastav, Nicolas Padoy
- **URL:** https://arxiv.org/abs/2507.05020
- **요약 (영문):** traditional models lack flexibility, requiring a separate model for each . a key challenge in multi-task learning is multitask learning .
- **요약 (한글):** 기존 모델은 유연성이 부족하여 각각에 대해 별도의 모델이 필요합니다. 멀티태스크 학습의 핵심 과제는 멀티태스크 학습입니다.

## 52. Meta-Learning Transformers to Improve In-Context Generalization
- **Authors:** Lorenzo Braccaioli, Anna Vettoruzzo, Prabhant Singh, Joaquin Vanschoren, Mohamed-Rafik Bouguelia, Nicola Conci
- **URL:** https://arxiv.org/abs/2507.05019
- **요약 (영문):** in-context learning enables transformer models to generalize to new tasks based solely on input prompts . however, existing training paradigms typically rely on large, unstructured datasets that are costly to store, difficult to evaluate for quality and balance, and pose privacy and ethical concerns .
- **요약 (한글):** 인컨텍스트 학습을 통해 트랜스포머 모델은 입력 프롬프트만을 기반으로 새로운 작업에 일반화할 수 있지만, 기존의 학습 패러다임은 일반적으로 저장 비용이 많이 들고 품질과 균형을 평가하기 어렵고 개인정보 보호 및 윤리적 문제가 있는 대규모 비정형 데이터 세트에 의존합니다.

## 53. Multi-modal Representations for Fine-grained Multi-label Critical View of Safety Recognition
- **Authors:** Britty Baby, Vinkle Srivastav, Pooja P. Jain, Kun Yuan, Pietro Mascagni, Nicolas Padoy
- **URL:** https://arxiv.org/abs/2507.05007
- **요약 (영문):** traditional models for CVS recognition depend on vision-only models learning with costly, labor-intensive spatial annotations . this study investigates how text can be harnessed as a powerful tool for both training and inference in multi-modal surgical foundation models .
- **요약 (한글):** CVS 인식을 위한 기존 모델은 비용이 많이 들고 노동 집약적인 공간 주석으로 학습하는 시각 전용 모델에 의존합니다. 이 연구에서는 멀티 모달 수술 기반 모델에서 텍스트를 훈련과 추론 모두를 위한 강력한 도구로 활용하는 방법을 조사합니다.

## 54. Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning
- **Authors:** Ruihao Zhang, Fei Ye, Dandan Meng, Yixuan Huang, Maochen, Xiao Liu
- **URL:** https://arxiv.org/abs/2507.04981
- **요약 (영문):** we developed EAMil, a multi-instance deep learning framework that leverages TCR sequencing data to diagnose systemic lupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional accuracy . by integrating PrimeSeq feature extraction with enhanced gate attention mechanisms, our model achi .
- **요약 (한글):** 우리는 TCR 시퀀싱 데이터를 활용하여 전신성 홍반성 루푸스(SLE)와 류마티스 관절염(RA)을 탁월한 정확도로 진단하는 멀티 인스턴스 딥러닝 프레임워크인 EAMil을 개발했습니다. PrimeSeq 특징 추출을 향상된 게이트 주의 메커니즘과 통합하여 우리의 모델 achi .

## 55. LAPS-Diff: A Diffusion-Based Framework for Singing Voice Synthesis With Language Aware Prosody-Style Guided Learning
- **Authors:** Sandipan Dhar, Mayank Gupta, Preeti Rao
- **URL:** https://arxiv.org/abs/2507.04966
- **요약 (영문):** the field of Singing Voice Synthesis (SVS) has seen significant advancements in recent years due to the rapid progress of diffusion-based approaches . however, capturing vocal style, genre-specific pitch inflections, and language-dependent characteristics remains challenging, particularly in low-resource scenarios . to address this, we propose a vocal-style guided learning mechanism, specifically designed for Bollywood Hindi singing st .
- **요약 (한글):** 노래 음성 합성(SVS) 분야는 최근 몇 년 동안 확산 기반 접근법의 빠른 발전으로 인해 상당한 발전을 보였습니다. 그러나 보컬 스타일, 장르별 음정 굴절 및 언어 의존적 특성을 캡처하는 것은 특히 리소스가 적은 시나리오에서 여전히 어려운 과제입니다. 이를 해결하기 위해 볼리우드 힌디어 노래를 위해 특별히 설계된 보컬 스타일 가이드 학습 메커니즘을 제안합니다.

## 56. Hear-Your-Click: Interactive Video-to-Audio Generation via Object-aware Contrastive Audio-Visual Fine-tuning
- **Authors:** Yingshan Liang, Keyu Fan, Zhicheng Du, Yiran Wang, Qingyang Shi, Xinyu Zhang, Jiasheng Lu, Peiwu Qin
- **URL:** https://arxiv.org/abs/2507.04959
- **요약 (영문):** video-to-audio (V2A) generation shows great potential in fields such as film production . current methods struggle with complex scenes and often fail to generate audio tailored to specific objects in the videos . to address these limitations, we introduce Hear-Your-Click, an interactive V2A framework that enables users to generate sounds for specific objects .
- **요약 (한글):** 비디오-오디오(V2A) 생성은 영화 제작과 같은 분야에서 큰 잠재력을 보여줍니다. 현재의 방법은 복잡한 장면에서 어려움을 겪고 있으며 비디오의 특정 개체에 맞는 오디오를 생성하지 못하는 경우가 많습니다. 이러한 한계를 해결하기 위해 사용자가 특정 개체에 맞는 소리를 생성할 수 있는 대화형 V2A 프레임워크인 Hear-Your-Click을 소개합니다.

## 57. EXPOTION: Facial Expression and Motion Control for Multimodal Music Generation
- **Authors:** Fathinah Izzati, Xinyue Li, Gus Xia
- **URL:** https://arxiv.org/abs/2507.04955
- **요약 (영문):** we propose a generative model leveraging multimodal visual controls . we adopt parametric fine-tuning (PEFT) on the pretrained text-to-music generation model .
- **요약 (한글):** 멀티모달 시각적 컨트롤을 활용한 생성 모델을 제안합니다. 사전 학습된 텍스트-음악 생성 모델에 파라메트릭 미세 조정(PEFT)을 채택합니다.

## 58. DC-AR: Efficient Masked Autoregressive Image Generation with Deep Compression Hybrid Tokenizer
- **Authors:** Yecheng Wu, Junyu Chen, Zhuoyang Zhang, Enze Xie, Jincheng Yu, Junsong Chen, Jinyi Hu, Yao Lu, Song Han, Han Cai
- **URL:** https://arxiv.org/abs/2507.04947
- **요약 (영문):** prior masked AR models have lagged behind diffusion models in terms of quality or efficiency . we introduce DC-HT - a deep compression hybrid tokenizer for AR models that achieve a 32x spatial compression ratio .
- **요약 (한글):** 이전의 마스크드 AR 모델은 품질이나 효율성 측면에서 디퓨전 모델에 비해 뒤쳐져 있었습니다. 유니티는 32배의 공간 압축률을 달성하는 AR 모델용 딥 압축 하이브리드 토큰나이저인 DC-HT를 소개합니다.

## 59. Object-centric Denoising Diffusion Models for Physical Reasoning
- **Authors:** Moritz Lange, Raphael C. Engelhardt, Wolfgang Konen, Andrew Melnik, Laurenz Wiskott
- **URL:** https://arxiv.org/abs/2507.04920
- **요약 (영문):** physical reasoning involves conditions imposed on the objects at different time steps . existing approaches in physical reasoning generally rely on autoregressive modeling .
- **요약 (한글):** 물리적 추론에는 다양한 시간 단계에서 객체에 부과된 조건이 포함되며, 물리적 추론의 기존 접근 방식은 일반적으로 자동 회귀 모델링에 의존합니다.

## 60. Leadership Detection via Time-Lagged Correlation-Based Network Inference
- **Authors:** Thayanne França da Silva, José Everardo Bessa Maia
- **URL:** https://arxiv.org/abs/2507.04917
- **요약 (영문):** traditional information-theoretic approaches have been widely used to infer leader-follower relationships . but they face critical limitations in noisy or short-duration datasets due to robust probability estimations .
- **요약 (한글):** 전통적인 정보 이론적 접근법은 리더와 팔로워의 관계를 추론하는 데 널리 사용되어 왔지만, 강력한 확률 추정으로 인해 잡음이 많거나 짧은 기간의 데이터 세트에서는 심각한 한계에 직면합니다.

## 61. HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding
- **Authors:** Yuxuan Cai, Jiangning Zhang, Zhenye Gan, Qingdong He, Xiaobin Hu, Junwei Zhu, Yabiao Wang, Chengjie Wang, Zhucun Xue, Xinwei He, Xiang Bai
- **URL:** https://arxiv.org/abs/2507.04909
- **요약 (영문):** multimodal Large Language Models (MLLMs) have demonstrated significant advances in visual understanding tasks involving both images and videos . however, their capacity to comprehend human-centric video data remains underexplored .
- **요약 (한글):** 다중 모드 대규모 언어 모델(MLLM)은 이미지와 동영상을 모두 포함하는 시각적 이해 작업에서 상당한 발전을 보여 왔지만, 인간 중심의 비디오 데이터를 이해하는 능력은 여전히 미개척 분야로 남아 있습니다.

## 62. BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning
- **Authors:** Thinh Dao, Dung Thuy Nguyen, Khoa D Doan, Kok-Seng Wong
- **URL:** https://arxiv.org/abs/2507.04903
- **요약 (영문):** backdoor attacks are vulnerable to backdoor attack . adversaries train their local models on poisoned data . divergent experimental settings, implementation errors, and unrealistic assumptions hinder fair comparisons and valid conclusions .
- **요약 (한글):** 백도어 공격에 취약합니다. 공격자는 오염된 데이터로 로컬 모델을 학습시킵니다. 서로 다른 실험 설정, 구현 오류 및 비현실적인 가정은 공정한 비교와 유효한 결론을 방해합니다.

## 63. Emergent Semantics Beyond Token Embeddings: Transformer LMs with Frozen Visual Unicode Representations
- **Authors:** A. Bochkov
- **URL:** https://arxiv.org/abs/2507.04886
- **요약 (영문):** the dominant paradigm posits that trainable input embeddings serve as foundational "meaning vectors" this paper challenges that view . we construct Transformer models where the embedded layer is entirely frozen .
- **요약 (한글):** 지배적인 패러다임은 훈련 가능한 입력 임베딩이 기초적인 '의미 벡터' 역할을 한다고 가정하는데, 이 논문은 이러한 관점에 도전합니다. 임베딩 계층이 완전히 고정된 트랜스포머 모델을 구축합니다.

## 64. Beyond Training-time Poisoning: Component-level and Post-training Backdoors in Deep Reinforcement Learning
- **Authors:** Sanyam Vyas, Alberto Caron, Chris Hicks, Pete Burnap, Vasilios Mavroudis
- **URL:** https://arxiv.org/abs/2507.04883
- **요약 (영문):** existing research focuses solely on training-time attacks requiring unrealistic access to the training pipeline . there are critical vulnerabilities across the DRL supply chain wheez .
- **요약 (한글):** 기존 연구는 훈련 파이프라인에 대한 비현실적인 접근이 필요한 훈련 시간 공격에만 초점을 맞추고 있습니다. DRL 공급망 전반에 걸쳐 심각한 취약점이 존재합니다.

## 65. HGNet: High-Order Spatial Awareness Hypergraph and Multi-Scale Context Attention Network for Colorectal Polyp Detection
- **Authors:** Xiaofang Liu, Lingling Sun, Xuqing Zhang, Yuannong Ye, Bin zhao
- **URL:** https://arxiv.org/abs/2507.04880
- **요약 (영문):** colorectal cancer is closely linked to the malignant transformation of polyps . current models struggle with detecting small lesions, accurately localizing boundaries, and providing interpretable decisions .
- **요약 (한글):** 대장암은 용종의 악성 변형과 밀접한 관련이 있습니다. 현재 모델은 작은 병변을 감지하고 경계를 정확하게 찾아내며 해석 가능한 결정을 내리는 데 어려움을 겪고 있습니다.

## 66. A Novel Approach for Estimating Positive Lyapunov Exponents in One-Dimensional Chaotic Time Series Using Machine Learning
- **Authors:** A. Velichko, M. Belyaev, P. Boriskov
- **URL:** https://arxiv.org/abs/2507.04868
- **요약 (영문):** the Lyapunov exponent is a key measure of chaotic behavior . its accurate estimation from experimental data is often hindered by methodological and computational limitations .
- **요약 (한글):** 리아푸노프 지수는 혼란스러운 행동의 핵심 척도입니다. 실험 데이터로부터의 정확한 추정은 종종 방법론적 및 계산적 한계로 인해 방해를 받습니다.

## 67. Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu
- **Authors:** António Sá Pinto
- **URL:** https://arxiv.org/abs/2507.04858
- **요약 (영문):** we explore transfer learning strategies for musical onset detection in the afro-brazilian Maracatu tradition . using only 5-second annotated snippets per instrument, we fine-tune these models through layer-wise retraining strategies .
- **요약 (한글):** 아프리카 브라질 마라카투 전통에서 음악 시작 감지를 위한 전이 학습 전략을 살펴봅니다. 악기당 5초 분량의 주석이 달린 스니펫만 사용하여 계층별 재교육 전략을 통해 이러한 모델을 미세 조정합니다.

## 68. Fast-VGAN: Lightweight Voice Conversion with Explicit Control of F0 and Duration Parameters
- **Authors:** Mathilde Abrassart, Nicolas Obin, Axel Roebel
- **URL:** https://arxiv.org/abs/2507.04817
- **요약 (영문):** the ability to manipulate parameters like pitch, duration, and speech rate remains a challenge in the field of voice conversion . in this work, we explore a convolutional neural network-based approach that aims to provide means for voice transformation .
- **요약 (한글):** 음성 변환 분야에서 피치, 지속 시간, 말하기 속도와 같은 매개 변수를 조작하는 능력은 여전히 과제로 남아 있습니다. 이 작업에서는 음성 변환을위한 수단을 제공하는 것을 목표로하는 컨볼 루션 신경망 기반 접근 방식을 살펴 봅니다.

## 69. From Vision To Language through Graph of Events in Space and Time: An Explainable Self-supervised Approach
- **Authors:** Mihai Masala, Marius Leordeanu
- **URL:** https://arxiv.org/abs/2507.04815
- **요약 (영문):** the task of describing video content in natural language is commonly referred to as video captioning . this limitation of current datasets is due to the expensive human manual annotation required and the highly challenging task of explaining the language formation process from the perspective of the underlying story .
- **요약 (한글):** 비디오 콘텐츠를 자연어로 설명하는 작업을 일반적으로 비디오 캡션이라고 합니다. 현재 데이터 세트의 이러한 한계는 사람이 직접 주석을 달아야 하고, 기본 스토리의 관점에서 언어 형성 과정을 설명해야 하는 매우 까다로운 작업으로 인해 발생합니다.

## 70. A Survey of Pun Generation: Datasets, Evaluations and Methodologies
- **Authors:** Yuchen Su, Yonghua Zhu, Ruofan Wang, Zijian Huang, Diana Benavides-Prado, Michael Witbrock
- **URL:** https://arxiv.org/abs/2507.04793
- **요약 (영문):** pun generation seeks to create humour or evoke double meanings . it also aims to preserve coherence and contextual appropriateness . there is currently no dedicated survey that reviews this specific area .
- **요약 (한글):** 말장난 생성은 유머를 만들거나 이중 의미를 불러 일으키려고합니다. 또한 일관성과 문맥의 적절성을 유지하는 것을 목표로합니다. 현재이 특정 영역을 검토하는 전용 설문 조사는 없습니다.

## 71. Model Compression using Progressive Channel Pruning
- **Authors:** Jinyang Guo, Weichen Zhang, Wanli Ouyang, Dong Xu
- **URL:** https://arxiv.org/abs/2507.04792
- **요약 (영문):** progressive channel pruning framework consists of a three-step attempting-selecting-pruning pipeline in each iteration . in the attempting step, we attain a small number of channels from several selected layers .
- **요약 (한글):** 프로그레시브 채널 가지치기 프레임워크는 각 반복에서 시도-선택-가지치기 파이프라인의 3단계로 구성되며, 시도 단계에서는 선택한 여러 레이어에서 적은 수의 채널을 얻습니다.

## 72. Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning
- **Authors:** Giwon Lee, Wooseong Jeong, Daehee Park, Jaewoo Jeong, Kuk-Jin Yoon
- **URL:** https://arxiv.org/abs/2507.04790
- **요약 (영문):** we propose interaction-Merged Motio to address these challenges . we propose a framework for autonomous robot driving . the framework is a key component of autonomous robots .
- **요약 (한글):** 우리는 이러한 문제를 해결하기 위해 인터랙션-병합 모티오를 제안합니다. 우리는 자율 로봇 주행을 위한 프레임워크를 제안합니다. 이 프레임워크는 자율 로봇의 핵심 구성 요소입니다.

## 73. From Imitation to Innovation: The Emergence of AI Unique Artistic Styles and the Challenge of Copyright Protection
- **Authors:** Zexi Jia, Chuanwei Huang, Yeshuang Zhu, Hongyan Fei, Ying Deng, Zhiqiang Yuan, Jiapei Zhang, Jinchao Zhang, Jie Zhou
- **URL:** https://arxiv.org/abs/2507.04769
- **요약 (영문):** current legal frameworks consider AI-generated works eligible for copyright protection when they meet originality requirements and involve substantial human intellectual input . systematic legal standards and reliable evaluation methods for AI art copyrights are lacking .
- **요약 (한글):** 현행 법체계는 인공지능이 생성한 저작물이 독창성 요건을 충족하고 인간의 지적 투입이 상당 부분 포함된 경우 저작권 보호 대상으로 간주하고 있으나, 인공지능 예술 저작권에 대한 체계적인 법적 기준과 신뢰할 수 있는 평가 방법이 부족합니다.

## 74. CoSteer: Collaborative Decoding-Time Personalization via Local Delta Steering
- **Authors:** Hang Lv, Sheng Liang, Hao Wang, Hongchao Gu, Yaxiong Wu, Wei Guo, Defu Lian, Yong Liu, Enhong Chen
- **URL:** https://arxiv.org/abs/2507.04756
- **요약 (영문):** existing methods often rely on centralized fine-tuning or static preference alignment . large cloud-based models lack access to localized user-specific information .
- **요약 (한글):** 기존 방식은 중앙 집중식 미세 조정 또는 정적 기본 설정 조정에 의존하는 경우가 많으며, 대규모 클라우드 기반 모델은 현지화된 사용자별 정보에 대한 액세스가 부족합니다.

## 75. Large Language Models for Network Intrusion Detection Systems: Foundations, Implementations, and Future Directions
- **Authors:** Shuo Yang, Xinran Zheng, Xinchen Zhang, Jinfeng Xu, Jinze Li, Donglin Xie, Weicai Long, Edith C.H. Ngai
- **URL:** https://arxiv.org/abs/2507.04752
- **요약 (영문):** large language models (LLMs) have revolutionized various fields with their exceptional capabilities in understanding, processing, and generating human-like text . this paper investigates the potential of LLMs in advancing NIDS .
- **요약 (한글):** 대규모 언어 모델(LLM)은 인간과 유사한 텍스트를 이해하고 처리하며 생성하는 탁월한 능력으로 다양한 분야에 혁신을 일으켰습니다. 이 백서에서는 NIDS를 발전시키는 데 있어 LLM의 잠재력을 살펴봅니다.

## 76. MCFormer: A Multi-Cost-Volume Network and Comprehensive Benchmark for Particle Image Velocimetry
- **Authors:** Zicheng Lin (International School, Beijing University of Posts and Telecommunications), Xiaoqiang Li (College of Engineering, Peking University), Yichao Wang (College of Physics and Optoelectronic Engineering, Harbin Engineering University), Chuan Zhu (School of Artificial Intelligence, Beijing University of Posts and Telecommunications)
- **URL:** https://arxiv.org/abs/2507.04750
- **요약 (영문):** the lack of comprehensive evaluation of how diverse optical flow models perform specifically on PIV data prevents fair comparison and hinders progress . to address this, our primary contribution is a novel, large-scale synthetic PIV benchmark dataset generated from available datasets .
- **요약 (한글):** 다양한 광학 흐름 모델이 PIV 데이터에서 구체적으로 어떻게 작동하는지에 대한 포괄적인 평가가 부족하여 공정한 비교를 방해하고 발전을 저해합니다. 이를 해결하기 위해 유니티는 사용 가능한 데이터 세트에서 생성된 새로운 대규모 합성 PIV 벤치마크 데이터 세트를 제공합니다.

## 77. Word stress in self-supervised speech models: A cross-linguistic comparison
- **Authors:** Martijn Bentum, Louis ten Bosch, Tomas O. Lentz
- **URL:** https://arxiv.org/abs/2507.04738
- **요약 (영문):** in this paper we study word stress representations learned by self-supervised speech models (S3M), specifically the Wav2vec 2.0 model . we train diagnostic stress classifiers on S3M embeddings .
- **요약 (한글):** 이 논문에서는 자기 지도 음성 모델(S3M), 특히 Wav2vec 2.0 모델에 의해 학습된 단어 강세 표현을 연구하고, S3M 임베딩에 대한 진단 강세 분류기를 훈련합니다.

## 78. Losing Control: Data Poisoning Attack on Guided Diffusion via ControlNet
- **Authors:** Raz Lapid, Almog Dubin
- **URL:** https://arxiv.org/abs/2507.04726
- **요약 (영문):** text-to-image diffusion models have achieved remarkable success in translating textual prompts into high-fidelity images . controlNets allows precise, image-based conditioning (e.g., edge maps, depth, pose), allowing fine-grained control over structure and style .
- **요약 (한글):** 텍스트-이미지 확산 모델은 텍스트 프롬프트를 고퀄리티 이미지로 변환하는 데 괄목할 만한 성공을 거두었습니다. controlNets는 정밀한 이미지 기반 컨디셔닝(예: 에지 맵, 깊이, 포즈)을 지원하여 구조와 스타일을 세밀하게 제어할 수 있습니다.

## 79. Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems
- **Authors:** Yizhe Xie, Congcong Zhu, Xinyue Zhang, Minghao Wang, Chi Liu, Minglu Zhu, Tianqing Zhu
- **URL:** https://arxiv.org/abs/2507.04724
- **요약 (영문):** multi-agent systems powered by Large Language Models (LLM-MAS) demonstrate remarkable capabilities in collaborative problem-solving . we design four representative attack paradigms that subtly disrupt task completion while maintaining high concealment.
- **요약 (한글):** 대규모 언어 모델(LLM-MAS)로 구동되는 멀티 에이전트 시스템은 협업 문제 해결에 탁월한 역량을 발휘하며, 높은 은폐성을 유지하면서 작업 완료를 교묘하게 방해하는 네 가지 대표적인 공격 패러다임을 설계합니다.

## 80. Geometric-Guided Few-Shot Dental Landmark Detection with Human-Centric Foundation Model
- **Authors:** Anbang Wang, Marawan Elbatel, Keyuan Liu, Lizhuo Lin, Meng Lan, Yanqi Yang, Xiaomeng Li
- **URL:** https://arxiv.org/abs/2507.04710
- **요약 (영문):** manual annotation of landmarks on cone-beam computed tomography is time-consuming, labor-intensive, and subject to inter-observer variability .
- **요약 (한글):** 콘빔 컴퓨터 단층 촬영에서 랜드마크에 수동 주석을 다는 작업은 시간이 많이 걸리고 노동 집약적이며 관찰자 간 변수가 발생할 수 있습니다.

## 81. UrbanMind: Towards Urban General Intelligence via Tool-Enhanced Retrieval-Augmented Generation and Multilevel Optimization
- **Authors:** Kai Yang, Zelin Zhu, Chengtao Jian, Hui Ma, Shengjie Zhao, Xiaozhou Ye, Ye Ouyang
- **URL:** https://arxiv.org/abs/2507.04706
- **요약 (영문):** central to UrbanMind is a novel architecture based on Continual Retrieval-Augmented MoE-based LLM (C-RAG-LLM) which dynamically incorporates domain-specific knowledge and evolving urban data to support long-term adaptabilities .
- **요약 (한글):** UrbanMind의 핵심은 도메인별 지식과 진화하는 도시 데이터를 동적으로 통합하여 장기적인 적응력을 지원하는 지속적 검색 증강 MoE 기반 LLM(C-RAG-LLM)을 기반으로 하는 새로운 아키텍처입니다.

## 82. SPATIA: Multimodal Model for Prediction and Generation of Spatial Cell Phenotypes
- **Authors:** Zhenglun Kong, Mufan Qiu, John Boesen, Xiang Lin, Sukwon Yun, Tianlong Chen, Manolis Kellis, Marinka Zitnik
- **URL:** https://arxiv.org/abs/2507.04704
- **요약 (영문):** image-based spatial transcriptomics technologies now provide high-resolution measurements of cell images and gene expression profiles . machine learning methods typically analyze these modalities in isolation or at limited resolution .
- **요약 (한글):** 이미지 기반 공간 전사체학 기술은 이제 세포 이미지와 유전자 발현 프로파일의 고해상도 측정을 제공합니다. 머신러닝 방법은 일반적으로 이러한 양식을 분리하여 또는 제한된 해상도로 분석합니다.

## 83. Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning
- **Authors:** Feng Yue, Zhaoxing Zhang, Junming Jiao, Zhengyu Liang, Shiwen Cao, Feifei Zhang, Rong Shen
- **URL:** https://arxiv.org/abs/2507.04702
- **요약 (영문):** videos often have a larger volume of information and redundancy than texts or images . we propose Tempo-R0: a Video Multimodal Large Language Model (Video-MLLM) for the temporal video grounding.
- **요약 (한글):** 비디오는 텍스트나 이미지보다 정보의 양이 많고 중복되는 경우가 많기 때문에 시간적 비디오 접지를 위한 비디오 멀티모달 대용량 언어 모델(Video-MLLM)인 Tempo-R0을 제안합니다.

## 84. Bridging KAN and MLP: MJKAN, a Hybrid Architecture with Both Efficiency and Expressiveness
- **Authors:** Hanseon Joo, Hayoung Choi, Ook Lee, Minjong Cheon
- **URL:** https://arxiv.org/abs/2507.04690
- **요약 (영문):** Kolmogorov-Arnold Networks proposes the Modulation Joint KAN . MJKAN integrates a FiLM (Feature-wise Linear Modulation)-like mechanism with Radial Basis Function (RBF) activation .
- **요약 (한글):** 콜모고로프-아놀드 네트웍스는 변조 조인트 KAN 을 제안합니다. MJKAN은 FiLM(기능별 선형 변조)과 유사한 메커니즘을 방사형 기저 함수(RBF) 활성화와 통합합니다.

## 85. Identify, Isolate, and Purge: Mitigating Hallucinations in LVLMs via Self-Evolving Distillation
- **Authors:** Wenhao Li, Xiu Su, Jingyi Wu, Feng Yang, Yang Liu, Yi Chen, Shan You, Chang Xu
- **URL:** https://arxiv.org/abs/2507.04680
- **요약 (영문):** large vision-language models have demonstrated remarkable advancements in numerous areas such as multimedia . however, hallucination issues significantly limit their credibility and application potential .
- **요약 (한글):** 대형 비전 언어 모델은 멀티미디어와 같은 다양한 분야에서 괄목할 만한 발전을 보여 왔지만, 환각 문제로 인해 신뢰성과 적용 가능성이 크게 제한되고 있습니다.

## 86. What's Making That Sound Right Now? Video-centric Audio-Visual Localization
- **Authors:** Hahyeon Choi, Junhoo Lee, Nojun Kwak
- **URL:** https://arxiv.org/abs/2507.04667
- **요약 (영문):** existing studies focus on image-level audio-visual associations . they assume simplified scenarios where sound sources are always visible and involve only a single object .
- **요약 (한글):** 기존 연구는 이미지 수준의 시청각 연관성에 초점을 맞추고 있으며, 음원이 항상 표시되고 단일 객체만 포함되는 단순화된 시나리오를 가정합니다.

## 87. LTMSformer: A Local Trend-Aware Attention and Motion State Encoding Transformer for Multi-Agent Trajectory Prediction
- **Authors:** Yixin Yan, Yang Li, Yuanfan Wang, Xiaozhou Zhou, Beihao Xia, Manjiang Hu, Hongmao Qin
- **URL:** https://arxiv.org/abs/2507.04634
- **요약 (영문):** capturing the local temporal dependency is beneficial for prediction, while most studies often overlook it . to address this, we propose a lightweight framework .
- **요약 (한글):** 국소적인 시간적 의존성을 포착하는 것은 예측에 도움이 되지만, 대부분의 연구는 이를 간과하는 경우가 많습니다. 이를 해결하기 위해 경량 프레임워크를 제안합니다.

## 88. Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts
- **Authors:** Yun Wang, Longguang Wang, Chenghao Zhang, Yongjian Zhang, Zhanjie Zhang, Ao Ma, Chenyou Fan, Tin Lun Lam, Junjie Hu
- **URL:** https://arxiv.org/abs/2507.04631
- **요약 (영문):** learning-based stereo matching networks have advanced significantly . but they often lack robustness due to domain shifts and imbalanced disparity distributions . integrating such a model into stereo matching cost-effectively remains a key challenge .
- **요약 (한글):** 학습 기반 스테레오 매칭 네트워크는 크게 발전했지만 도메인 이동과 불균형한 격차 분포로 인해 견고성이 부족한 경우가 많습니다. 이러한 모델을 비용 효율적으로 스테레오 매칭에 통합하는 것은 여전히 핵심 과제로 남아 있습니다.

## 89. Knowledge-Aware Self-Correction in Language Models via Structured Memory Graphs
- **Authors:** Swayamjit Saha
- **URL:** https://arxiv.org/abs/2507.04625
- **요약 (영문):** large language models (LLMs) are powerful yet prone to generating factual errors, commonly referred to as hallucinations . our method post-processes model outputs and corrects factual inconsistencies via external semantic memory .
- **요약 (한글):** 대규모 언어 모델(LLM)은 강력하지만 흔히 환각이라고 불리는 사실 오류를 발생시키기 쉽습니다. 우리의 방법은 모델 출력을 후처리하고 외부 시맨틱 메모리를 통해 사실 불일치를 수정합니다.

## 90. Hierarchical Intent-guided Optimization with Pluggable LLM-Driven Semantics for Session-based Recommendation
- **Authors:** Jinpeng Chen, Jianxiang He, Huan Li, Senzhang Wang, Yuan Cao, Kaimin Wei, Zhenye Yang, Ye Ji
- **URL:** https://arxiv.org/abs/2507.04623
- **요약 (영문):** Existing SBR models often focus only on single-session information . some methods try to include inter-session data but struggle with noise and irrelevant information, reducing performance .
- **요약 (한글):** 기존 SBR 모델은 단일 세션 정보에만 초점을 맞추는 경우가 많으며, 일부 방법은 세션 간 데이터를 포함하려고 시도하지만 노이즈와 관련 없는 정보로 인해 성능이 저하되는 문제가 있습니다.

## 91. Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences
- **Authors:** Yusong Zhang, Yuxuan Sun, Lei Guo, Wei Chen, Bo Ai, Deniz Gunduz
- **URL:** https://arxiv.org/abs/2507.04621
- **요약 (영문):** 6G networks promise revolutionary communication experiences including augmented reality (AR), virtual reality (VR) and holographic communications . these applications require high-dimensional multimodal data transmission and intelligent data processing in real-time .
- **요약 (한글):** 6G 네트워크는 증강현실(AR), 가상현실(VR), 홀로그램 통신 등 혁신적인 통신 경험을 약속합니다. 이러한 애플리케이션에는 고차원 멀티모달 데이터 전송과 실시간 지능형 데이터 처리가 필요합니다.

## 92. Information-Guided Diffusion Sampling for Dataset Distillation
- **Authors:** Linfeng Ye, Shayan Mohajer Hamidi, Guang Li, Takahiro Ogawa, Miki Haseyama, Konstantinos N. Plataniotis
- **URL:** https://arxiv.org/abs/2507.04619
- **요약 (영문):** dataset distillation aims to create a compact dataset that retains essential information while maintaining model performance . this paper addresses this issue from an information-theoretic perspective by identifying two key types of information a distilled dataset must preserve .
- **요약 (한글):** 데이터 세트 증류는 모델 성능을 유지하면서 필수 정보를 유지하는 압축 데이터 세트를 만드는 것을 목표로 합니다. 이 백서에서는 증류된 데이터 세트가 보존해야 하는 두 가지 주요 정보 유형을 식별하여 정보 이론적 관점에서 이 문제를 다룹니다.

## 93. HiLa: Hierarchical Vision-Language Collaboration for Cancer Survival Prediction
- **Authors:** Jiaqi Cui, Lu Wen, Yuchen Fei, Bo Liu, Luping Zhou, Dinggang Shen, Yan Wang
- **URL:** https://arxiv.org/abs/2507.04613
- **요약 (영문):** survival prediction using whole-slide images (WSIs) is crucial in cancer re-search . existing approaches are limited by their reliance on sparse slide-level labels, which hinder the learning of discriminative repre-sentations .
- **요약 (한글):** 전체 슬라이드 이미지(WSI)를 사용한 생존 예측은 암 재검색에서 매우 중요합니다. 기존 접근 방식은 희박한 슬라이드 수준의 라벨에 의존하기 때문에 변별력 있는 재현 학습을 방해하는 한계가 있습니다.

## 94. any4: Learned 4-bit Numeric Representation for LLMs
- **Authors:** Mostafa Elhoushi, Jeff Johnson
- **URL:** https://arxiv.org/abs/2507.04610
- **요약 (영문):** any4 is a learned 4-bit weight quantization solution for large language models . it provides arbitrary numeric representations without pre-processing of weights or activations .
- **요약 (한글):** any4는 대규모 언어 모델을 위한 학습된 4비트 가중치 양자화 솔루션으로, 가중치나 활성화의 사전 처리 없이 임의의 숫자 표현을 제공합니다.

## 95. PRIME: Large Language Model Personalization with Cognitive Memory and Thought Processes
- **Authors:** Xinliang Frederick Zhang, Nick Beauchamp, Lu Wang
- **URL:** https://arxiv.org/abs/2507.04607
- **요약 (영문):** large language model personalization aims to align model outputs with individual's unique preferences and opinions . we integrate the well-established cognitive dual-memory model into LLM personalization by mirroring episodic memory to historical user engagements .
- **요약 (한글):** 대규모 언어 모델 개인화는 모델 결과물을 개인의 고유한 선호도 및 의견에 맞추는 것을 목표로 하며, 잘 확립된 인지 이중 메모리 모델을 과거 사용자 참여에 에피소드 메모리를 미러링하여 LLM 개인화에 통합합니다.

## 96. Accelerated Online Reinforcement Learning using Auxiliary Start State Distributions
- **Authors:** Aman Mehra, Alexandre Capone, Jeff Schneider
- **URL:** https://arxiv.org/abs/2507.04606
- **요약 (영문):** a long-standing problem in online reinforcement learning stems from an inability to explore environments efficiently . such approaches fail to leverage expert demonstrations and simulators that can reset to arbitrary states .
- **요약 (한글):** 온라인 강화 학습의 오랜 문제는 환경을 효율적으로 탐색할 수 없다는 데서 비롯됩니다. 이러한 접근 방식은 전문가 데모와 임의의 상태로 재설정할 수 있는 시뮬레이터를 활용하지 못합니다.
