## arXiv cs.AI 논문 요약 Digest - 2025-06-26

### 1. JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning
- Authors: Ai Han, Junxing Hu, Pu Wei, Zhiqian Zhang, Yuhang Guo, Jiawei Lu, Zicheng Zhang
- URL: https://arxiv.org/abs/2506.19846
- 요약 (영문): multi-agent reinforcement learning has emerged as a prominent paradigm for increasingly complex tasks . however, joint evolution across heterogeneous agents remains challenging due to cooperative inefficiency and training instability .
- 요약 (한글): 다중 에이전트 강화 학습은 점점 더 복잡해지는 작업에 대한 중요한 패러다임으로 부상했지만, 협력 비효율성과 훈련 불안정성으로 인해 이기종 에이전트 간의 공동 진화는 여전히 어려운 과제로 남아 있습니다.

### 2. Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning
- Authors: Guo Li, Zixiang Xu, Wei Zhang, Yikuan Hu, Xinyu Yang, Nikolay Aristov, Mingjie Tang, Elenna R Dugundji
- URL: https://arxiv.org/abs/2506.19843
- 요약 (영문): forecasts enableimprovedshipment planning, reducedelaysand costs, and optimizeinventoryanddistributionstrategies . to achieve accurate predictions, analyzing vessel behavior and stay times at specific port terminals is essential .
- 요약 (한글): 예측을 통해 선적 계획 개선, 지연 및 비용 절감, 재고 및 유통 전략 최적화가 가능합니다. 정확한 예측을 위해서는 특정 항만 터미널에서의 선박 행동과 체류 시간을 분석하는 것이 필수적입니다.

### 3. Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models
- Authors: Johannes Rückert, Louise Bloch, Christoph M. Friedrich
- URL: https://arxiv.org/abs/2506.19825
- 요약 (영문): the research field of data visualization deals with defining principles and guidelines for the creation and use of diagrams . diagrams are often not known or adhered to by researchers, leading to misinformation caused by inaccurate information .
- 요약 (한글): 데이터 시각화 연구 분야는 다이어그램의 생성 및 사용에 대한 원칙과 지침을 정의하는 것을 다루며, 연구자들이 다이어그램을 잘 모르거나 준수하지 않아 부정확한 정보로 인한 잘못된 정보로 이어지는 경우가 많습니다.

### 4. KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality
- Authors: Baochang Ren, Shuofei Qiao, Wenhao Yu, Huajun Chen, Ningyu Zhang
- URL: https://arxiv.org/abs/2506.19807
- 요약 (영문): Large Language Models (LLMs) often exhibit severe hallucination due to an inability to accurately recognize knowledge boundaries during reasoning . lms often lack factual supervision over the thinking process, exacerbating the problem in slow-thinking models .
- 요약 (한글): 대규모 언어 모델(LLM)은 추론 중 지식 경계를 정확하게 인식하지 못해 심각한 환각을 보이는 경우가 많으며, 사고 과정에 대한 사실적 감독이 부족하여 느린 사고 모델의 문제를 악화시키는 경우가 많습니다.

### 5. Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning
- Authors: Menglong Zhang, Fuyuan Qian
- URL: https://arxiv.org/abs/2506.19785
- 요약 (영문): meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks . recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal .
- 요약 (한글): 메타 강화 학습은 탐색 중에 얻은 사전 작업 분포 정보를 활용하여 미지의 작업에 빠르게 적응해야 합니다. 최근의 베이지안 적응형 딥 RL 접근 방식은 종종 환경의 보상 신호를 재구성하는 데 의존합니다.

### 6. SAGE: Strategy-Adaptive Generation Engine for Query Rewriting
- Authors: Teng Wang, Hailei Gong, Changwang Zhang, Jun Wang
- URL: https://arxiv.org/abs/2506.19783
- 요약 (영문): we first establish that guiding Large Language Models (LLMs) improves retrieval effectiveness on challenging benchmarks, including hotpotQA, FEVER, NFCorpus and SciFact .
- 요약 (한글): 먼저 대규모 언어 모델(LLM)을 안내하면 hotpotQA, FEVER, NFCorpus 및 SciFact 를 비롯한 까다로운 벤치마크에서 검색 효율성이 향상된다는 사실을 확인했습니다.

### 7. Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study
- Authors: Nandana Mihindukulasooriya, Niharika S. D'Souza, Faisal Chowdhury, Horst Samulowitz
- URL: https://arxiv.org/abs/2506.19773
- 요약 (영문): KGs are used for various applications, including semantic search and discovery, reasoning, decision-making, natural language processing, machine learning, and recommendation systems . triple extraction from text is the fundamental building block of KG construction .
- 요약 (한글): KG는 시맨틱 검색 및 발견, 추론, 의사 결정, 자연어 처리, 머신 러닝, 추천 시스템 등 다양한 애플리케이션에 사용되며, 텍스트에서 삼중 추출은 KG 구축의 기본 구성 요소입니다.

### 8. From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking
- Authors: Gyeongwon James Kim, Alex Wilf, Louis-Philippe Morency, Daniel Fried
- URL: https://arxiv.org/abs/2506.19724
- 요약 (영문): autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments . there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point .
- 요약 (한글): 자율 코드 생성은 실험을 실행하여 과학적 발견을 가속화할 수 있는 AI 에이전트에 대한 관심을 불러 일으켰습니다. 현재 다양한 양의 코드가 시작점으로 주어졌을 때 이러한 에이전트가 과학적 아이디어를 구현할 수 있는지 평가하는 벤치마크는 없습니다.

### 9. LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis
- Authors: Lei Kang, Xuanshuo Fu, Oriol Ramos Terrades, Javier Vazquez-Corral, Ernest Valveny, Dimosthenis Karatzas
- URL: https://arxiv.org/abs/2506.19702
- 요약 (영문): medical document analysis plays a crucial role in extracting clinical insights from unstructured healthcare records . the most probable condition among overlapping symptoms requires precise evaluation and deep medical expertise . privacy concerns related to sensitive patient data limit the use of online LMs .
- 요약 (한글): 의료 문서 분석은 구조화되지 않은 의료 기록에서 임상 인사이트를 추출하는 데 중요한 역할을 합니다. 중복되는 증상 중 가장 가능성이 높은 상태는 정밀한 평가와 심도 있는 의료 전문 지식이 필요합니다. 민감한 환자 데이터와 관련된 개인정보 우려는 온라인 LM의 사용을 제한합니다.

### 10. Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance
- Authors: Zhuojun Xie, Adam Abdin, Yiping Fang
- URL: https://arxiv.org/abs/2506.19698
- 요약 (영문): research increasingly integrates machine learning (ML) into predictive maintenance (PdM) to reduce operational and maintenance costs in data-rich operational settings . uncertainty due to model misspecification continues to limit widespread industrial adoption .
- 요약 (한글): 데이터가 풍부한 운영 환경에서 운영 및 유지 관리 비용을 줄이기 위해 머신 러닝(ML)을 예측 유지 관리(PdM)에 통합하는 연구가 증가하고 있으며, 모델 잘못된 사양으로 인한 불확실성으로 인해 산업계의 광범위한 채택이 계속 제한되고 있습니다.

### 11. From memories to maps: Mechanisms of in context reinforcement learning in transformers
- Authors: Ching Fang, Kanaka Rajan
- URL: https://arxiv.org/abs/2506.19686
- 요약 (영문): humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience . this capability is not well captured by standard reinforcement learning algorithms . Transformers provide a useful setting for studying these questions .
- 요약 (한글): 인간과 동물은 최소한의 경험으로 새로운 환경에 적응하는 놀라운 학습 효율성을 보여줍니다 . 이 능력은 표준 강화 학습 알고리즘으로는 잘 포착되지 않습니다. 트랜스포머는 이러한 문제를 연구하는 데 유용한 환경을 제공합니다.

### 12. Identifying Macro Causal Effects in C-DMGs over DMGs
- Authors: Simon Ferreira, Charles K. Assaad
- URL: https://arxiv.org/abs/2506.19650
- 요약 (영문): the do-calculus is a sound and complete tool for identifying causal effects in acyclic directed mixed graphs (ADMGs) induced by structural causal models (SCMs) this limitation has led to growing interest in partially specified causal representations .
- 요약 (한글): 도-미적분은 구조적 인과 모델(SCM)에 의해 유도된 비순환 방향 혼합 그래프(ADMG)에서 인과 효과를 식별하기 위한 건전하고 완벽한 도구입니다. 이러한 한계로 인해 부분적으로 지정된 인과 표현에 대한 관심이 높아졌습니다 .

### 13. On the efficacy of old features for the detection of new bots
- Authors: Rocco De Nicola, Marinella Petrocchi, Manuel Pratelli
- URL: https://arxiv.org/abs/2506.19635
- 요약 (영문): academicians and online platform administrators have been studying bot detection . bots are computer algorithms whose use is far from benign . they are purposely created to distribute spam, sponsor public characters and induce bias within the public opinion .
- 요약 (한글): 학자들과 온라인 플랫폼 관리자들은 봇 탐지에 대해 연구해 왔습니다. 봇은 컴퓨터 알고리즘으로, 그 사용 목적이 양성과는 거리가 멀며, 스팸을 배포하고 대중을 후원하며 여론의 편견을 유도하기 위해 의도적으로 만들어집니다.

### 14. Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI
- Authors: Sha Zhang, Suorong Yang, Tong Xie, Xiangyuan Xue, Zixuan Hu, Rui Li, Wenxi Qu, Zhenfei Yin, Tianfan Fu, Di Hu, Andres M Bran, Nian Ran, Bram Hoex, Wangmeng Zuo, Philippe Schwaller, Wanli Ouyang, Lei Bai, Yanyong Zhang, Lingyu Duan, Shixiang Tang, Dongzhan Zhou
- URL: https://arxiv.org/abs/2506.19613
- 요약 (영문): the recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research . however, key limitations persist: AI systems are often confined to virtual environments .
- 요약 (한글): 최근 AI 과학자와 자동화된 실험실의 등장으로 연구의 인지적 측면과 운영 측면이 모두 가속화되었지만 주요 한계는 여전히 남아 있습니다: AI 시스템은 종종 가상 환경에 국한되어 있습니다.

### 15. ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP
- Authors: Zhiyuan Wang, Bokui Chen
- URL: https://arxiv.org/abs/2506.19608
- 요약 (영문): Continual learning (CLIP) empowers pre-trained vision-language models to adapt effectively to novel or previously underrepresented data distributions without comprehensive retraining . existing prompt learning methods face two main limitations: 1) they primarily focus on class-incremental learning scenarios, lacking specie .
- 요약 (한글): 지속적인 학습(CLIP)은 사전 학습된 시각 언어 모델이 포괄적인 재교육 없이도 새로운 또는 이전에 잘 알려지지 않은 데이터 분포에 효과적으로 적응할 수 있도록 지원합니다. 기존의 신속한 학습 방법은 두 가지 주요 한계에 직면해 있습니다: 1) 주로 클래스 점진적 학습 시나리오에 초점을 맞추며, 종 .

### 16. Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning
- Authors: Harisankar Babu, Philipp Schillinger, Tamim Asfour
- URL: https://arxiv.org/abs/2506.19592
- 요약 (영문): TAPAS is a multi-agent framework that integrates large language models with symbolic planning . agents can create and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms .
- 요약 (한글): TAPAS는 대규모 언어 모델을 기호적 계획과 통합하는 멀티 에이전트 프레임워크로, 에이전트는 구조화된 도구 호출 메커니즘을 사용하여 필요에 따라 도메인 모델, 초기 상태 및 목표 사양을 생성하고 조정할 수 있습니다.

### 17. Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming
- Authors: Sanne Wielinga, Jesse Heyninck
- URL: https://arxiv.org/abs/2506.19573
- 요약 (영문): ML techniques play a pivotal role in high-stakes domains such as healthcare . but most high-performing methods are often opaque, limiting trust .
- 요약 (한글): ML 기술은 의료와 같은 중요한 영역에서 중추적인 역할을 하지만, 대부분의 고성능 방법은 불투명하여 신뢰가 제한되는 경우가 많습니다.

### 18. NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons
- Authors: Carlo Romeo, Andrew D. Bagdanov
- URL: https://arxiv.org/abs/2506.19530
- 요약 (영문): in this paper, we propose an approach that automates combat encounter design in D&D . NTRL generates encounters based october 1 based on a contextual bandit .
- 요약 (한글): 이 백서에서는 D&D 에서 전투 조우 설계를 자동화하는 접근 방식을 제안합니다. NTRL은 컨텍스트 밴딧을 기반으로 10월 1일을 기준으로 조우를 생성합니다.

### 19. NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling
- Authors: Yan Jiang, Hao Zhou, LiZhong GU, Ai Han, TianLong Li
- URL: https://arxiv.org/abs/2506.19500
- 요약 (영문): reliance on static knowledge and fragile tool invocation severely hinders the orchestration of complex, heterogeneous toolchains . existing methods typically use rigid single-path execution, resulting in poor error recovery .
- 요약 (한글): 정적 지식에 대한 의존과 취약한 도구 호출은 복잡한 이기종 툴체인의 오케스트레이션을 심각하게 방해합니다. 기존 방법은 일반적으로 경직된 단일 경로 실행을 사용하므로 오류 복구가 제대로 이루어지지 않습니다.

### 20. KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models
- Authors: Cheng Li, Jiexiong Liu, Yixuan Chen, Qihang Zhou, KunLun Meta
- URL: https://arxiv.org/abs/2506.19466
- 요약 (영문): KunLunBaizeRAG is a reinforcement learning-driven reasoning framework . framework addresses key limitations of traditional RAG . key innovations include retrieval drift, information redundancy, and strategy rigidity .
- 요약 (한글): 쿤룬베이즈RAG는 강화 학습 기반 추론 프레임워크로, 기존 RAG의 주요 한계를 해결하고 검색 드리프트, 정보 중복성, 전략 경직성 등 주요 혁신 사항을 해결합니다.

### 21. Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection
- Authors: Yazhou Zhang, Chunwang Zou, Bo Wang, Jing Qin
- URL: https://arxiv.org/abs/2506.19420
- 요약 (영문): large language models (LLMs) have shown impressive performance on many downstream NLP tasks . growing evidence suggests that they struggle with sarcasm understanding . commander-GPT orchestrates a team of specialized LLM agents .
- 요약 (한글): 대규모 언어 모델(LLM)은 많은 다운스트림 NLP 작업에서 인상적인 성능을 보였습니다. 풍자 이해에 어려움을 겪고 있다는 증거가 늘어나고 있습니다. commander-GPT는 전문 LLM 에이전트로 구성된 팀을 조율합니다.

### 22. Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification
- Authors: Anas Hattay, Mayara Ayat, Fred Ngole Mboula
- URL: https://arxiv.org/abs/2506.19410
- 요약 (영문): the paper introduces a novel approach for totally unsupervised robust clustering . traditional methods often lack adaptability to diverse datasets . u-daDiL aligns distributions from different datasets using waterstein barycenter based representation .
- 요약 (한글): 이 논문은 완전히 비지도된 강력한 클러스터링을 위한 새로운 접근법을 소개합니다. 기존의 방법은 종종 다양한 데이터 세트에 대한 적응성이 부족합니다. u-daDiL은 워터스타인 바리센터 기반 표현을 사용하여 다양한 데이터 세트의 분포를 정렬합니다.

### 23. Is an object-centric representation beneficial for robotic manipulation ?
- Authors: Alexandre Chapin (imagine), Emmanuel Dellandrea (imagine), Liming Chen (imagine)
- URL: https://arxiv.org/abs/2506.19408
- 요약 (영문): Object-centric representation has become a subject of interest in the computer vision community for learning a structured representation of images and videos . most existing work only evaluates such models on scene decomposition, without any notion of reasoning over the learned representation .
- 요약 (한글): 객체 중심 표현은 이미지와 비디오의 구조화된 표현을 학습하기 위해 컴퓨터 비전 커뮤니티에서 관심의 대상이 되었습니다. 대부분의 기존 작업은 학습된 표현에 대한 추론 개념 없이 장면 분해에 대해서만 이러한 모델을 평가합니다.

### 24. Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics
- Authors: Ziqi Zhu, Tao Hu, Honglong Zhang, Dan Yang, HanGeng Chen, Mengran Zhang, Xilun Chen
- URL: https://arxiv.org/abs/2506.19385
- 요약 (영문): we present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval Augmented Generation) framework addresses limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression .
- 요약 (한글): 문맥의 일관성과 목표 지향적 진행을 모두 유지하는 데 있어 기존 대화 시스템의 한계를 해결하는 CID-GraphRAG(대화 의도 기반 그래프 검색 증강 생성) 프레임워크를 소개합니다.

### 25. Evolutionary Level Repair
- Authors: Debosmita Bhaumik, Julian Togelius, Georgios N. Yannakakis, Ahmed Khalifa
- URL: https://arxiv.org/abs/2506.19359
- 요약 (영문): the problem of game level repair may consist of ensuring the completeness of the level, reachability of objects, or other performance characteristics . the problem may also be constrained in that it can only make a small number of changes to the level .
- 요약 (한글): 게임 레벨 복구의 문제는 레벨의 완성도, 오브젝트의 도달 가능성 또는 기타 성능 특성을 보장하는 것으로 구성될 수 있습니다. 또한 레벨을 소량만 변경할 수 있다는 점에서 문제가 제한될 수 있습니다.

### 26. FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring
- Authors: Hyein Seo, Taewook Hwang, Yohan Lee, sangkeun Jung
- URL: https://arxiv.org/abs/2506.19325
- 요약 (영문): in english education tutoring, teacher feedback is essential for guiding students . in recent years, AI-based tutoring systems have emerged to assist teachers . however, these systems require high-quality and large-scale teacher feedback data, which is costly to generate manually .
- 요약 (한글): 영어 교육 과외에서 교사의 피드백은 학생들을 지도하는 데 필수적입니다. 최근에는 교사를 보조하는 AI 기반 과외 시스템이 등장했습니다. 그러나 이러한 시스템에는 고품질의 대규모 교사 피드백 데이터가 필요하며 수동으로 생성하는 데 많은 비용이 듭니다.

### 27. Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs
- Authors: Liang Zeng, Yongcong Li, Yuzhen Xiao, Changshi Li, Chris Yuhao Liu, Rui Yan, Tianwen Wei, Jujie He, Xuchen Song, Yang Liu, Yahui Zhou
- URL: https://arxiv.org/abs/2506.19290
- 요약 (영문): the data curation process in SWE remains notoriously time-consuming . it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments .
- 요약 (한글): SWE의 데이터 큐레이션 프로세스는 여전히 시간이 많이 소요되는 것으로 악명이 높으며, 코드 파일 필터링과 전용 런타임 환경 설정을 위한 수동 주석에 크게 의존하고 있습니다.

### 28. Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach
- Authors: Feiting Yang, Antoine Moevus, Steve Lévesque
- URL: https://arxiv.org/abs/2506.19280
- 요약 (영문): human-computer interaction (HCI) has evolved significantly to incorporate emotion recognition capabilities . this paper explores the integration of emotion detection into calendar applications .
- 요약 (한글): 인간-컴퓨터 상호 작용(HCI)은 감정 인식 기능을 통합하기 위해 크게 발전해 왔습니다. 이 백서에서는 캘린더 애플리케이션에 감정 감지를 통합하는 방법을 살펴봅니다.

### 29. RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1
- Authors: Yu Xie, Xingkai Ren, Ying Qi, Yao Hu, Lianlei Shan
- URL: https://arxiv.org/abs/2506.19235
- 요약 (영문): this paper introduces a novel recommendation framework leveraging Large Language Models . the framework initiates by transforming user profiles, historical interactions, and multi-faceted item attributes into LLM-interprepretation .
- 요약 (한글): 이 백서에서는 대규모 언어 모델을 활용하는 새로운 추천 프레임워크를 소개합니다. 이 프레임워크는 사용자 프로필, 과거 상호 작용 및 다면적인 항목 속성을 LLM 해석으로 변환하는 것으로 시작됩니다.

### 30. GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing
- Authors: Shuyin Xia, Guan Wang, Gaojie Xu, Sen Zhao, Guoyin Wang
- URL: https://arxiv.org/abs/2506.19224
- 요약 (영문): previous work were mainly based on the perspective of spectrum-preserving . they used some predefined coarsening rules to make the eigenvalues of the Laplacian matrix of the original graph and the coarsened graph match as much as possible .
- 요약 (한글): 이전 작업은 주로 스펙트럼 보존이라는 관점에 기반을 두었습니다. 그들은 원본 그래프의 라플라시안 행렬과 거친 그래프의 고유값을 최대한 일치시키기 위해 미리 정의된 몇 가지 거친화 규칙을 사용했습니다.

### 31. Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation
- Authors: Xingyang Li, Muyang Li, Tianle Cai, Haocheng Xi, Shuo Yang, Yujun Lin, Lvmin Zhang, Songlin Yang, Jinbo Hu, Kelly Peng, Maneesh Agrawala, Ion Stoica, Kurt Keutzer, Song Han
- URL: https://arxiv.org/abs/2506.19852
- 요약 (영문): advances in diffusion models have enabled high-quality video generation . but the additional temporal dimension significantly increases computational costs . this paper identifies a phenomenon we term Spatiotemporal Energy Decay in video diffusion models .
- 요약 (한글): 확산 모델의 발전으로 고품질 비디오 생성이 가능해졌지만, 시간적 차원이 추가되면 계산 비용이 크게 증가합니다. 이 논문에서는 비디오 확산 모델에서 시공간적 에너지 쇠퇴라고 부르는 현상을 확인합니다.

### 32. Orthogonal Finetuning Made Scalable
- Authors: Zeju Qiu, Weiyang Liu, Adrian Weller, Bernhard Schölkopf
- URL: https://arxiv.org/abs/2506.19847
- 요약 (영문): the core computational bottleneck in OFT is its weight-centric implementation . it relies on costly matrix-matrix multiplications with cubic complexity . to overcome this, we propose OFTv2 .
- 요약 (한글): OFT의 핵심 계산 병목 현상은 가중치 중심의 구현입니다. 이는 입방 복잡성을 가진 값비싼 행렬-행렬 곱셈에 의존합니다. 이를 극복하기 위해 OFTv2 를 제안합니다.

### 33. Improving Progressive Generation with Decomposable Flow Matching
- Authors: Moayed Haji-Ali, Willi Menapace, Ivan Skorokhodov, Arpit Sahni, Sergey Tulyakov, Vicente Ordonez, Aliaksandr Siarohin
- URL: https://arxiv.org/abs/2506.19839
- 요약 (영문): the outputs are synthesized in a coarse-to-fine spectral autoregressive manner . explicit multi-stage architectures have increased complexity of the overall approach .
- 요약 (한글): 출력은 거칠고 미세한 스펙트럼 자동 회귀 방식으로 합성됩니다. 명시적인 다단계 아키텍처는 전체 접근 방식의 복잡성을 증가시켰습니다.

### 34. A standard transformer and attention with linear biases for molecular conformer generation
- Authors: Viatcheslav Gurev, Timothy Rumbell
- URL: https://arxiv.org/abs/2506.19834
- 요약 (영문): specialized equivariant networks have been designed to generate molecular conformations from 2D graphs . a number of specialized models have emerged as a viable alternative due to their capability to scale .
- 요약 (한글): 2D 그래프에서 분자 형태를 생성하기 위해 특수한 등변량 네트워크가 설계되었으며, 확장 기능으로 인해 여러 특수 모델이 실행 가능한 대안으로 부상했습니다.

### 35. Persona Features Control Emergent Misalignment
- Authors: Miles Wang, Tom Dupré la Tour, Olivia Watkins, Alex Makelov, Ryan A. Chi, Samuel Miserendino, Johannes Heidecke, Tejal Patwardhan, Dan Mossing
- URL: https://arxiv.org/abs/2506.19823
- 요약 (영문): fine-tuning GPT-4o on intentionally insecure code causes "emergent misalignment" models give stereotypically malicious responses to unrelated prompts . we extend this work, demonstrating emergent misalignement across diverse conditions .
- 요약 (한글): 의도적으로 안전하지 않은 코드에 대해 GPT-4o를 미세 조정하면 "긴급한 오정렬" 모델이 관련 없는 프롬프트에 고정관념적으로 악의적인 반응을 일으킵니다. 이 작업을 확장하여 다양한 조건에서 긴급한 오정렬을 입증했습니다.

### 36. Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study
- Authors: Yuqi Zhu, Yi Zhong, Jintian Zhang, Ziheng Zhang, Shuofei Qiao, Yujie Luo, Lun Du, Da Zheng, Huajun Chen, Ningyu Zhang
- URL: https://arxiv.org/abs/2506.19794
- 요약 (영문): large language models (LLMs) hold promise in automating data analysis tasks . but open-source models face significant limitations in these kinds of reasoning-intensive scenarios .
- 요약 (한글): 대규모 언어 모델(LLM)은 데이터 분석 작업을 자동화하는 데 유망하지만, 오픈 소스 모델은 이러한 종류의 추론 집약적인 시나리오에서 상당한 한계에 직면합니다.

### 37. Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model
- Authors: Yang Liu, Feng Wu, Xuefang Zhu
- URL: https://arxiv.org/abs/2506.19777
- 요약 (영문): recommendation systems are driven by user behavior . users with the same sensitive feature tend to have the same patterns . DM's ability to model uncemented features has achieved great success .
- 요약 (한글): 추천 시스템은 사용자 행동에 의해 구동됩니다. 동일한 민감한 기능을 가진 사용자는 동일한 패턴을 갖는 경향이 있습니다. 확정되지 않은 특징을 모델링하는 DM의 능력은 큰 성공을 거두었습니다.

### 38. Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation
- Authors: Jun Wang, Xijuan Zeng, Chunyu Qiang, Ruilong Chen, Shiyao Wang, Le Wang, Wangjing Zhou, Pengfei Cai, Jiahui Zhao, Nan Li, Zihan Li, Yuzhe Liang, Xiaopeng Wang, Haorui Zheng, Ming Wen, Kang Yin, Yiran Wang, Nan Li, Feng Deng, Liang Dong, Chen Zhang, Di Zhang, Kun Gai
- URL: https://arxiv.org/abs/2506.19774
- 요약 (영문): Kling-Foley is a large-scale multimodal model that synthesizes high-quality audio synchronized with video content . we introduce multimodal diffusion transformers to model the interactions between video, audio, and text modalities .
- 요약 (한글): 클링-폴리는 비디오 콘텐츠와 동기화된 고품질 오디오를 합성하는 대규모 멀티모달 모델로, 비디오, 오디오, 텍스트 모달리티 간의 상호작용을 모델링하기 위해 멀티모달 확산 변환기를 도입합니다.

### 39. A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects
- Authors: Shulan Ruan, Rongwei Wang, Xuchen Shen, Huijie Liu, Baihui Xiao, Jun Shi, Kun Zhang, Zhenya Huang, Yu Liu, Enhong Chen, You He
- URL: https://arxiv.org/abs/2506.19769
- 요약 (영문): multi-sensor fusion perception (MSFP) is a key technology for embodied AI . it can serve a variety of downstream tasks (e.g., 3D object detection and semantic segmentation) and application scenarios . the existing surveys have some limitations after a rigorous investigation .
- 요약 (한글): 다중 센서 융합 인식(MSFP)은 구현된 AI를 위한 핵심 기술로, 다양한 다운스트림 작업(예: 3D 객체 감지 및 시맨틱 분할) 및 응용 시나리오를 지원할 수 있으며, 기존 조사는 엄격한 조사 후 몇 가지 한계가 있습니다.

### 40. SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning
- Authors: Yuqian Fu, Tinghong Chen, Jiajun Chai, Xihuai Wang, Songjun Tu, Guojun Yin, Wei Lin, Qichao Zhang, Yuanheng Zhu, Dongbin Zhao
- URL: https://arxiv.org/abs/2506.19767
- 요약 (영문): the optimal integration of Supervised Fine-Tuning and Reinforcement Learning (RL) remains a fundamental challenge . RL performs fine-grained selective optimizing .
- 요약 (한글): 감독 미세 조정과 강화 학습(RL)의 최적 통합은 여전히 근본적인 과제로 남아 있습니다. RL은 세분화된 선택적 최적화를 수행합니다.

### 41. Cross-regularization: Adaptive Model Complexity through Validation Gradients
- Authors: Carlos Stein Brito
- URL: https://arxiv.org/abs/2506.19755
- 요약 (영문): model regularization requires extensive manual tuning to balance complexity against overfitting . method splits parameter optimization - training data guides feature learning while validation data shapes complexity controls .
- 요약 (한글): 모델 정규화는 복잡성과 과적합의 균형을 맞추기 위해 광범위한 수동 조정이 필요합니다. 메서드 분할 파라미터 최적화 - 학습 데이터는 기능 학습을 안내하고 검증 데이터는 복잡성 제어를 형성합니다.

### 42. Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis
- Authors: Omar A.Essameldin, Ali O.Elbeih, Wael H.Gomaa, Wael F.Elsersy
- URL: https://arxiv.org/abs/2506.19753
- 요약 (영문): the Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries . MARBERTv2 performed best with 65% accuracy and 64% F1-score .
- 요약 (한글): 아랍어는 22개국에서 다양한 방언이 사용되는 세계에서 가장 인기 있는 언어 중 하나입니다. MARBERTv2는 65%의 정확도와 64%의 F1 점수로 최고의 성능을 보였습니다.

### 43. NeRF-based CBCT Reconstruction needs Normalization and Initialization
- Authors: Zhuowei Xu, Han Li, Dai Sun, Zhicheng Li, Yujia Li, Qingpeng Kong, Zhiwei Cheng, Nassir Navab, S. Kevin Zhou
- URL: https://arxiv.org/abs/2506.19742
- 요약 (영문): cone beam computed tomography (CBCT) is widely used in medical imaging . but the limited number and intensity of X-ray projections make reconstruction an ill-posed problem with severe artifacts .
- 요약 (한글): 콘빔 컴퓨터 단층 촬영(CBCT)은 의료 영상에 널리 사용되지만, X-선 투영의 수와 강도가 제한되어 있어 심각한 아티팩트로 인해 재구성하는 데 어려움이 있습니다.

### 44. Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units
- Authors: Shrey Dixit, Kayson Fakhar, Fatemeh Hadaeghi, Patrick Mineault, Konrad P. Kording, Claus C. Hilgetag
- URL: https://arxiv.org/abs/2506.19732
- 요약 (영문): neural networks generate text, images, and speech with billions of parameters . existing explainable-AI methods, such as SHAP, attribute importance to inputs, but cannot quantify the contributions of neural units across thousands of output pixels .
- 요약 (한글): 신경망은 수십억 개의 파라미터로 텍스트, 이미지, 음성을 생성합니다. SHAP과 같은 기존의 설명 가능한 AI 방식은 입력에 중요성을 부여하지만 수천 개의 출력 픽셀에 걸쳐 신경 단위의 기여도를 정량화할 수 없습니다.

### 45. Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty
- Authors: Carlos Stein Brito
- URL: https://arxiv.org/abs/2506.19726
- 요약 (영문): existing variational inference methods often employ isotropic Gaussian approximations in weight space that poorly match the network's inherent geometry . CAP models weight uncertainties directly on the unit hypersphere using von Mises-Fisher distributions .
- 요약 (한글): 기존의 변형 추론 방법은 종종 네트워크의 고유한 기하학적 구조와 잘 맞지 않는 가중치 공간에서 등방성 가우시안 근사치를 사용합니다. CAP는 폰 미제스-피셔 분포를 사용하여 단위 하이퍼스피어에서 직접 불확실성을 가중치로 모델링합니다.

### 46. Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders
- Authors: Matyas Bohacek, Thomas Fel, Maneesh Agrawala, Ekdeep Singh Lubana
- URL: https://arxiv.org/abs/2506.19708
- 요약 (영문): generative image models trained on large-scale datasets often fail to produce images with seemingly simple concepts . these failure modes have been documented anecdotally, leaving open the question of whether they reflect more structural limitations .
- 요약 (한글): 대규모 데이터 세트에 대해 학습된 생성 이미지 모델은 종종 단순해 보이는 개념의 이미지를 생성하지 못합니다. 이러한 실패 모드는 일화적으로 문서화되어 있으며, 구조적 한계를 반영하는지에 대한 의문이 남아있습니다.

### 47. Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models
- Authors: Jungwoo Park, Taewhoo Lee, Chanwoong Yoon, Hyeon Hwang, Jaewoo Kang
- URL: https://arxiv.org/abs/2506.19697
- 요약 (영문): extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment . outlier-safe pre-Training (OSP) combines three key innovations: the Muon optimizer, eliminating privileged bb .
- 요약 (한글): 대규모 언어 모델(LLM)의 극단적인 활성화 이상값은 양자화 성능을 심각하게 저하시켜 효율적인 온디바이스 배포를 방해합니다. 이상값 안전 사전 학습(OSP)은 세 가지 핵심 혁신, 즉 뮤온 옵티마이저, 특권 bb 제거를 결합합니다.

### 48. When Can We Reuse a Calibration Set for Multiple Conformal Predictions?
- Authors: A.A. Balinsky, A.D. Balinsky
- URL: https://arxiv.org/abs/2506.19689
- 요약 (영문): inductive conformal prediction offers a distribution-free framework for generating prediction sets or intervals with user-specified confidence . standard ICP guarantees are marginal and typically require a fresh calibration set for each new prediction .
- 요약 (한글): 유도적 컨포멀 예측은 사용자가 지정한 신뢰도로 예측 세트 또는 간격을 생성하기 위한 분포 없는 프레임워크를 제공합니다. 표준 ICP 보장은 한계가 있으며 일반적으로 새로운 예측마다 새로운 캘리브레이션 세트가 필요합니다.

### 49. Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance
- Authors: Xuesong Li, Dianye Huang, Yameng Zhang, Nassir Navab, Zhongliang Jiang
- URL: https://arxiv.org/abs/2506.19683
- 요약 (영문): new advances in large language models (LLMs) have been used to automatically generate terminology-rich summaries orientated to clinicians with sufficient physiological knowledge . increasing demand for improved ultrasound interpretability and basic scanning guidance among non-expert users .
- 요약 (한글): 대규모 언어 모델(LLM)의 새로운 발전으로 충분한 생리학 지식을 갖춘 임상의를 위한 용어가 풍부한 요약본을 자동으로 생성하는 데 사용되었습니다. 비전문가 사용자 사이에서 초음파 해석 가능성 개선 및 기본 스캔 지침에 대한 수요가 증가하고 있습니다.

### 50. Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager
- Authors: Lucie Galland, Catherine Pelachaud, Florian Pecune
- URL: https://arxiv.org/abs/2506.19652
- 요약 (영문): we propose a framework that integrates large language models with an RL-based dialogue manager for open-ended dialogue with a specific goal . by leveraging hierarchical reinforcement learning to model the structured phases of dialogue, our approach enhances adaptability and efficiency .
- 요약 (한글): 특정 목표를 가진 개방형 대화를 위해 대규모 언어 모델과 RL 기반 대화 관리자를 통합하는 프레임워크를 제안합니다. 계층적 강화 학습을 활용하여 구조화된 대화 단계를 모델링함으로써 적응성과 효율성을 향상시키는 접근 방식입니다.

### 51. The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs
- Authors: B. Paroli, F. Borghi, M.A.C. Potenza, P. Milani
- URL: https://arxiv.org/abs/2506.19642
- 요약 (영문): the linearity of TLGs limits classification capabilities requiring the use of networks for the accomplishment of complex tasks . a generalization of the TLG model called receptron allows for a significant enhancement of classification peptron .
- 요약 (한글): TLG의 선형성은 복잡한 작업을 수행하기 위해 네트워크를 사용해야 하는 분류 기능을 제한합니다. 리셉트론이라는 TLG 모델을 일반화하면 분류 펩트론을 크게 향상시킬 수 있습니다.

### 52. Hierarchical Time Series Forecasting Via Latent Mean Encoding
- Authors: Alessandro Salatiello, Stefan Birr, Manuel Kunz
- URL: https://arxiv.org/abs/2506.19633
- 요약 (영문): a new hierarchical architecture tackles this problem by leveraging modules that specialize in forecasting the different temporal aggregation levels of interest . the architecture learns to encode the average behaviour of the target variable across both coarse and fine temporal scales .
- 요약 (한글): 새로운 계층적 아키텍처는 관심 있는 다양한 시간적 집계 수준을 예측하는 데 특화된 모듈을 활용하여 이 문제를 해결합니다. 이 아키텍처는 거친 시간적 규모와 미세한 시간적 규모 모두에서 대상 변수의 평균 동작을 인코딩하는 방법을 학습합니다.

### 53. Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations
- Authors: Thomas Decker, Volker Tresp, Florian Buettner
- URL: https://arxiv.org/abs/2506.19630
- 요약 (영문): models often produce unreliable probability estimates when subjected to explainability-specifiable explanations . this paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy .
- 요약 (한글): 이 논문에서는 불확실성 보정(모델 신뢰도와 실제 정확도의 일치)과 불확실성 보정(모델 신뢰도의 일치)의 관계를 조사합니다.

### 54. VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks
- Authors: Noel José Rodrigues Vicente, Enrique Lehner, Angel Villar-Corrales, Jan Nogga, Sven Behnke
- URL: https://arxiv.org/abs/2506.19621
- 요약 (영문): unsupervised learning of object representations and dynamics remains challenging . videoPCDNet is an unsupervised framework for object-centric video decomposition and prediction .
- 요약 (한글): 객체 표현과 역학에 대한 비지도 학습은 여전히 어려운 과제입니다. videoPCDNet은 객체 중심 비디오 분해 및 예측을 위한 비지도 프레임워크입니다.

### 55. ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model
- Authors: Zhenke Duan, Jiqun Pan, Jiani Tu, Xiaoyi Wang, Yanqing Wang
- URL: https://arxiv.org/abs/2506.19599
- 요약 (영문): the chain of Thought (ECCoT) prompting method structures reasoning into step-by-step deductions . but not all reasoning chains are valid, and errors can lead to unreliable conclusions .
- 요약 (한글): 생각의 사슬(ECCoT) 유도 방법은 추론을 단계별 추론으로 구조화하지만 모든 추론 사슬이 유효한 것은 아니며 오류로 인해 신뢰할 수 없는 결론이 도출될 수 있습니다.

### 56. Robotics Under Construction: Challenges on Job Sites
- Authors: Haruki Uchiito, Akhilesh Bhat, Koji Kusaka, Xiaoya Zhang, Hiraku Kinjo, Honoka Uehara, Motoki Koyama, Shinji Natsume
- URL: https://arxiv.org/abs/2506.19597
- 요약 (영문): this paper presents an autonomous payload transportation system as an initial step toward fully unmanned construction sites . our system integrates autonomous navigation, fleet management, and GNSS-based localization to facilitate material transport .
- 요약 (한글): 이 논문은 완전 무인 건설 현장을 향한 초기 단계로서 자율적 페이로드 운송 시스템을 제시합니다. 우리의 시스템은 자율 항법, 차량 관리 및 GNSS 기반 현지화를 통합하여 자재 운송을 용이하게합니다.

### 57. Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications
- Authors: Lujun Li, Yiqun Wang, Radu State
- URL: https://arxiv.org/abs/2506.19591
- 요약 (영문): cloud cover in multispectral imagery poses significant challenges for early season crop mapping . we propose a new framework, time-series MSI Image Reconstruction using vision Transformer (ViT), to reconstruct MSI data in cloud-covered regions .
- 요약 (한글): 멀티 스펙트럼 이미지의 구름 덮개는 초기 시즌 작물 매핑에 상당한 문제를 야기합니다. 우리는 구름 덮인 지역에서 MSI 데이터를 재구성하기 위해 비전 트랜스포머(ViT)를 사용한 시계열 MSI 이미지 재구성이라는 새로운 프레임워크를 제안합니다.

### 58. Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects
- Authors: Federico Tavella, Kathryn Mearns, Angelo Cangelosi
- URL: https://arxiv.org/abs/2506.19579
- 요약 (영문): the robot collects images of objects from multiple viewpoints . we evaluate several models that generate scene descriptions . the robot is equipped with an RGB camera .
- 요약 (한글): 로봇이 여러 시점에서 물체의 이미지를 수집합니다 . 장면 설명을 생성하는 여러 모델을 평가합니다 . 로봇에 RGB 카메라가 장착되어 있습니다 .

### 59. Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures
- Authors: Ozgur O. Kilic, David K. Park, Yihui Ren, Tatiana Korchuganova, Sairam Sri Vatsavai, Joseph Boudreau, Tasnuva Chowdhury, Shengyu Feng, Raees Khan, Jaehyung Kim, Scott Klasky, Tadashi Maeno, Paul Nilsson, Verena Ingrid Martinez Outschoorn, Norbert Podhorszki, Frédéric Suter, Wei Yang, Yiming Yang, Shinjae Yoo, Alexei Klimentov, Adolfy Hoisie
- URL: https://arxiv.org/abs/2506.19578
- 요약 (영문): large-scale scientific collaborations involve hundreds of research institutes and thousands of researchers across the globe . these experiments generate petabytes of data, with volumes soon expected to reach exbytes . there is a growing need for computation, including structured data processing from raw data to consumer-ready derived data .
- 요약 (한글): 대규모 과학 협업에는 전 세계 수백 개의 연구 기관과 수천 명의 연구원이 참여합니다. 이러한 실험은 페타바이트의 데이터를 생성하며, 그 양은 곧 엑바이트에 이를 것으로 예상됩니다. 원시 데이터에서 소비자가 사용할 수 있는 파생 데이터까지 구조화된 데이터 처리를 포함한 계산에 대한 필요성이 점점 더 커지고 있습니다.

### 60. Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress
- Authors: Lorenzo Proietti, Stefano Perrella, Roberto Navigli
- URL: https://arxiv.org/abs/2506.19571
- 요약 (영문): metric performance is assessed based on agreement with human judgments . human annotators are not consistently superior to automatic metrics, with state-of-the-art metrics .
- 요약 (한글): 메트릭 성능은 사람의 판단에 대한 동의 여부에 따라 평가됩니다. 인간 어노테이터는 최첨단 메트릭을 사용하는 자동 메트릭보다 일관되게 우월하지 않습니다.

### 61. FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting
- Authors: Pengpeng Ouyang, Dong Chen, Tong Yang, Shuo Feng, Zhao Jin, Mingliang Xu
- URL: https://arxiv.org/abs/2506.19567
- 요약 (영문): traditional time series forecasting methods suffer from insufficient historical data . we propose the Feature-Adaptive Time Series Forecasting Framework (FAF)
- 요약 (한글): 기존의 시계열 예측 방법은 과거 데이터 부족으로 어려움을 겪습니다. 특징 적응형 시계열 예측 프레임워크(FAF)를 제안합니다.

### 62. PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty
- Authors: Jinwen He, Yiyang Lu, Zijin Lin, Kai Chen, Yue Zhao
- URL: https://arxiv.org/abs/2506.19563
- 요약 (영문): large Language Models (LLMs) are widely used in sensitive domains, including healthcare, finance, and legal services . privacy extraction attacks expose vulnerabilities in LLMs by crafting inputs that force the models to output sensitive information .
- 요약 (한글): 대규모 언어 모델(LLM)은 의료, 금융, 법률 서비스 등 민감한 도메인에서 널리 사용되며, 개인정보 추출 공격은 모델이 민감한 정보를 강제로 출력하도록 입력을 조작하여 LLM의 취약점을 노출시킵니다.

### 63. MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification
- Authors: Minjong Cheon, Changbae Mun
- URL: https://arxiv.org/abs/2506.19561
- 요약 (영문): the rise of state space models (SSMs) like Mamba has been celebrated for their linear scalability . however, their adaptation to 2D visual data often necessitates complex modifications that may diminish efficiency .
- 요약 (한글): 맘바와 같은 상태 공간 모델(SSM)의 등장은 선형 확장성으로 인해 찬사를 받았지만, 2D 시각 데이터에 적용하려면 종종 복잡한 수정이 필요해 효율성이 저하될 수 있습니다.

### 64. General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound
- Authors: Jakob Ambsdorf, Asbjørn Munk, Sebastian Llambias, Anders Nymark Christensen, Kamil Mikolaj, Randall Balestriero, Martin Tolsgaard, Aasa Feragen, Mads Nielsen
- URL: https://arxiv.org/abs/2506.19552
- 요약 (영문): researchers are confronted with two questions: should they pretrain a custom foundation model on this medical data or use transfer-learning from an existing generalist model? in this paper we train a foundation model in a large regional fetal ultrasound dataset of 2M images .
- 요약 (한글): 연구자들은 이 의료 데이터에 대해 맞춤형 파운데이션 모델을 사전 학습해야 하는지, 아니면 기존 제너럴리스트 모델의 전이 학습을 사용해야 하는지 두 가지 질문에 직면합니다. 이 논문에서는 2M 이미지의 대규모 지역 태아 초음파 데이터 세트에서 파운데이션 모델을 학습합니다.

### 65. RCStat: A Statistical Framework for using Relative Contextualization in Transformers
- Authors: Debabrata Mahapatra, Shubham Agarwal, Apoorv Saxena, Subrata Mitra
- URL: https://arxiv.org/abs/2506.19549
- 요약 (영문): prior work on input-token importance in auto-regressive transformers has relied on Softmax-normalized attention weights . we introduce RCStat, a statistical framework that harnesses raw attention logits via Relative Contextualization .
- 요약 (한글): 자동 회귀 변환기에서 입력-토큰 중요도에 대한 이전 작업은 Softmax 정규화된 주의 가중치에 의존해 왔습니다. 상대적 맥락화를 통해 원시 주의 로그를 활용하는 통계 프레임워크인 RCStat을 소개합니다.

### 66. Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language
- Authors: Julian Fragner, Christian Macho, Bernhard Dieber, Martin Pinzger
- URL: https://arxiv.org/abs/2506.19539
- 요약 (영문): log analytics tools and platforms were developed to help filter and extract information from logs . recent commercial log analytics platforms provide domain-specific languages specifically designed for log parsing .
- 요약 (한글): 로그 분석 도구와 플랫폼은 로그에서 정보를 필터링하고 추출하는 데 도움이 되도록 개발되었습니다. 최근 상용 로그 분석 플랫폼은 로그 구문 분석을 위해 특별히 설계된 도메인별 언어를 제공합니다.

### 67. ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation
- Authors: Mubashara Rehman, Niki Martinel, Michele Avanzo, Riccardo Spizzo, Christian Micheloni
- URL: https://arxiv.org/abs/2506.19531
- 요약 (영문): we propose a deep learning framework for metal artifact reduction (MAR) and domain transformation from kVCT to mega-Voltage CT . the proposed framework, ReMAR-DS, uses an encoder-decoder architecture with enhanced feature recalibration .
- 요약 (한글): 금속 아티팩트 감소(MAR)와 kVCT에서 메가 전압 CT로의 도메인 변환을 위한 딥러닝 프레임워크를 제안합니다. 제안된 프레임워크인 ReMAR-DS는 향상된 기능 재보정 기능을 갖춘 인코더-디코더 아키텍처를 사용합니다.

### 68. Automatic Posology Structuration : What role for LLMs?
- Authors: Natalia Bobkova, Laura Zanella-Calzada, Anyes Tafoughalt, Raphaël Teboul, François Plesse, Félix Gaschi
- URL: https://arxiv.org/abs/2506.19525
- 요약 (영문): posology instructions are often ambiguous, irregular, or colloquial . we compare prompt-based methods and fine-tuning against a "pre-LLM" system based on Named Entity Recognition and Linking .
- 요약 (한글): 포지톨로지 지침은 종종 모호하거나 불규칙하거나 구어체입니다. 프롬프트 기반 방법과 명명된 개체 인식 및 연결에 기반한 "LLM 이전" 시스템과 미세 조정을 비교합니다.

### 69. MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications
- Authors: Aleksandr Algazinov, Matt Laing, Paul Laban
- URL: https://arxiv.org/abs/2506.19502
- 요약 (영문): existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs . individuals with disabilities often encounter significant barriers when attempting to interact with digital environments .
- 요약 (한글): 기존의 멀티 에이전트 시스템(MAS)은 폐쇄형 설계로 인한 사용자 지정 부족으로 도움이 필요한 사용자에게 포괄적인 지원을 제공하지 못하는 경우가 많습니다. 장애가 있는 개인은 디지털 환경과 상호작용을 시도할 때 종종 상당한 장벽에 부딪힙니다.

### 70. Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications
- Authors: Genís Castillo Gómez-Raya, Álmos Veres-Vitályos, Filip Lemic, Pablo Royo, Mario Montagud, Sergi Fernández, Sergi Abadal, Xavier Costa-Pérez
- URL: https://arxiv.org/abs/2506.19491
- 요약 (영문): the increasing miniaturization of unmanned Aerial Vehicles (UAVs) has expanded their deployment potential to indoor and hard-to-reach areas . however, this trend introduces distinct challenges, particularly in terms of flight dynamics and power consumption, which limit the UAVs' autonomy and mission capabilities .
- 요약 (한글): 무인 항공기(UAV)의 소형화가 증가함에 따라 실내 및 접근이 어려운 지역으로 배치 가능성이 확대되었지만, 이러한 추세는 특히 비행 역학 및 전력 소비 측면에서 뚜렷한 문제를 야기하여 UAV의 자율성과 임무 수행 능력을 제한합니다.

### 71. Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy
- Authors: Zhihao Sui, Liang Hu, Jian Cao, Dora D. Liu, Usman Naseem, Zhongyuan Lai, Qi Zhang
- URL: https://arxiv.org/abs/2506.19486
- 요약 (영문): despite rapid advancements in MU technology, its vulnerabilities are still underexplored . current limited research requires access to original models containing privacy data .
- 요약 (한글): MU 기술의 급속한 발전에도 불구하고 그 취약성은 여전히 밝혀지지 않았습니다. 현재 제한된 연구에는 개인 정보 데이터가 포함된 원본 모델에 대한 액세스가 필요합니다.

### 72. Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning
- Authors: Russell Beale
- URL: https://arxiv.org/abs/2506.19484
- 요약 (영문): a comprehensive review of how LLM-based conversational agents are being used in higher education . we synthesize existing literature on LLMs in education and theories of conversational and dialogic pedagogy .
- 요약 (한글): LLM 기반 대화 에이전트가 고등 교육에서 어떻게 사용되고 있는지에 대한 종합적인 검토 교육에서의 LLM에 대한 기존 문헌과 대화 및 대화 교육학 이론을 종합합니다.

### 73. Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning
- Authors: Yuelin Zhang, Jiacheng Cen, Jiaqi Han, Wenbing Huang
- URL: https://arxiv.org/abs/2506.19482
- 요약 (영문): Equivariant Graph Neural Networks (GNNs) have achieved remarkable success across diverse scientific applications . existing approaches face critical efficiency challenges when scaling to large geometric graphs .
- 요약 (한글): 등변량 그래프 신경망(GNN)은 다양한 과학 응용 분야에서 놀라운 성공을 거두었습니다. 기존 접근 방식은 큰 기하학적 그래프로 확장할 때 중요한 효율성 문제에 직면합니다.

### 74. Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning
- Authors: Pengfei Hao, Shuaibo Li, Hongqiu Wang, Zhizhuo Kou, Junhang Zhang, Guang Yang, Lei Zhu
- URL: https://arxiv.org/abs/2506.19469
- 요약 (영문): in recent years, significant progress has been made in the field of surgical scene understanding . existing Surgical-VQLA models lack deep reasoning capabilities and interpretability .
- 요약 (한글): 최근 몇 년 동안 수술 장면 이해 분야에서 상당한 진전이 이루어졌습니다. 기존 수술-VQLA 모델은 심층 추론 능력과 해석 가능성이 부족합니다.

### 75. MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages
- Authors: Wenhan Han, Yifan Zhang, Zhixun Chen, Binbin Liu, Haobin Lin, Bingni Zhang, Taifeng Wang, Mykola Pechenizkiy, Meng Fang, Yin Zheng
- URL: https://arxiv.org/abs/2506.19468
- 요약 (영문): multilingual large language models (LLMs) are advancing rapidly . existing evaluation datasets are limited and lack cross-lingual alignment, leaving assessments fragmented in both language and skill coverage .
- 요약 (한글): 다국어 대규모 언어 모델(LLM)이 빠르게 발전하고 있습니다. 기존 평가 데이터 세트는 제한적이고 언어 간 조정이 부족하여 언어와 기술 범위 모두에서 평가가 단편적으로 이루어지고 있습니다.

### 76. Can Large Language Models Capture Human Annotator Disagreements?
- Authors: Jingwei Ni, Yu Fan, Vilém Zouhar, Donya Rooein, Alexander Hoyle, Mrinmaya Sachan, Markus Leippold, Dirk Hovy, Elliott Ash
- URL: https://arxiv.org/abs/2506.19467
- 요약 (영문): large language models (LLMs) are increasingly used for automatic annotation to reduce human effort . it is still unclear whether these models also capture informative human annotation variation .
- 요약 (한글): 사람의 노력을 줄이기 위해 자동 주석에 대규모 언어 모델(LLM)이 점점 더 많이 사용되고 있지만, 이러한 모델이 유익한 사람의 주석 변형을 포착하는지 여부는 아직 불분명합니다.

### 77. Stylized Structural Patterns for Improved Neural Network Pre-training
- Authors: Farnood Salehi, Vandit Sharma, Amirhossein Askari Farsangi, Tunç Ozan Aydın
- URL: https://arxiv.org/abs/2506.19465
- 요약 (영문): recent works suggest synthetic data as an alternative, yet models trained with it often underperform . this paper proposes a two-step approach to bridge this gap .
- 요약 (한글): 최근의 연구는 합성 데이터를 대안으로 제시하지만, 합성 데이터로 훈련된 모델은 종종 성능이 저하됩니다. 이 백서에서는 이러한 격차를 해소하기 위한 2단계 접근 방식을 제안합니다.

### 78. Iterative Quantum Feature Maps
- Authors: Nasa Matsumoto, Quoc Hoan Tran, Koki Chinzei, Yasuhiro Endo, Hirotaka Oshima
- URL: https://arxiv.org/abs/2506.19461
- 요약 (영문): quantum machine learning models leverage quantum circuits as quantum feature maps (QFMs) . such models have demonstrated rigorous end-to-end quantum speedups for specific families of classification problems .
- 요약 (한글): 양자 머신 러닝 모델은 양자 회로를 양자 특징 맵(QFM)으로 활용하며, 이러한 모델은 특정 분류 문제군에 대해 엄격한 엔드투엔드 양자 속도 향상을 입증했습니다.

### 79. Tagged for Direction: Pinning Down Causal Edge Directions with Precision
- Authors: Florian Peter Busch, Moritz Willig, Florian Guldan, Kristian Kersting, Devendra Singh Dhami
- URL: https://arxiv.org/abs/2506.19459
- 요약 (영문): causal discovery can be leveraged for the task of causal discovery . a tag-based causal discovery approach is used to assign a specific type to a variable .
- 요약 (한글): 인과 관계 발견 작업에는 태그 기반 인과 관계 발견 접근 방식을 사용하여 변수에 특정 유형을 할당할 수 있으며, 인과 관계 발견 작업에는 인과 관계 발견을 활용할 수 있습니다.

### 80. Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System
- Authors: Lixuan He, Haoyu Dong, Zhenxing Chen, Yangcheng Yu, Jie Feng, Yong Li
- URL: https://arxiv.org/abs/2506.19433
- 요약 (영문): vision-and-Language Navigation (VLN) requires embodied agents to ground linguistic instructions in complex scenes . prior modular pipelines offer interpretability but lack unified memory . end-to-end (M)LLM agents excel at fusing vision and language .
- 요약 (한글): 시각-언어 내비게이션(VLN)은 구현된 에이전트가 복잡한 장면에서 언어적 지침을 기반으로 해야 합니다. 이전의 모듈식 파이프라인은 해석 기능을 제공하지만 통합 메모리가 부족합니다. 엔드투엔드(M)LLM 에이전트는 시각과 언어를 융합하는 데 탁월합니다.

### 81. A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation
- Authors: Chen Yi, Shan LianLei
- URL: https://arxiv.org/abs/2506.19406
- 요약 (영문): the demand for accurate and efficient semantic segmentation has increased significantly with the rapid development of ultra-high resolution (UHR) remote sensing technology . existing methods face challenges in computational efficiency and multi-scale feature fusion .
- 요약 (한글): 초고해상도(UHR) 원격 센싱 기술의 급속한 발전으로 정확하고 효율적인 시맨틱 분할에 대한 수요가 크게 증가했습니다. 기존 방법은 계산 효율성과 멀티 스케일 특징 융합에 어려움을 겪고 있습니다.

### 82. Automated Detection of Pre-training Text in Black-box LLMs
- Authors: Ruihan Hu, Yu-Ming Shang, Jiankun Peng, Wei Luo, Yazhe Wang, Xi Zhang
- URL: https://arxiv.org/abs/2506.19399
- 요약 (영문): most existing methods rely on the LLM's hidden information (e.g., model parameters or token probabilities) making them ineffective in the black-box setting, where only input and output texts are accessible . some methods have been proposed for the setting but rely largely on manual efforts such as designing complicated questio .
- 요약 (한글): 대부분의 기존 방법은 LLM의 숨겨진 정보(예: 모델 파라미터 또는 토큰 확률)에 의존하기 때문에 입력 및 출력 텍스트만 접근할 수 있는 블랙박스 설정에서는 효과적이지 않습니다. 일부 방법이 제안되었지만 복잡한 쿼리 설계와 같은 수작업에 크게 의존하고 있습니다.

### 83. NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs
- Authors: Khuram Naveed, Bruna Neves de Freitas, Ruben Pauwels
- URL: https://arxiv.org/abs/2506.19387
- 요약 (영문): convolutional denoising autoencoders are powerful tools for image restoration . they tend to recover low-frequency features, such as smooth regions, more effectively than high-frequency details . this leads to the loss of fine details, which is particularly problematic in dental radiographs .
- 요약 (한글): 컨볼루션 노이즈 제거 자동 인코더는 이미지 복원을 위한 강력한 도구로, 고주파 디테일보다 부드러운 영역과 같은 저주파 특징을 더 효과적으로 복구하는 경향이 있습니다. 이로 인해 치과 방사선 사진에서 특히 문제가 되는 미세한 디테일이 손실될 수 있습니다.

### 84. From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data
- Authors: Yuanyuan Zhang, Haocheng Zhao, Sijie Xiong, Rui Yang, Eng Gee Lim, Yutao Yue
- URL: https://arxiv.org/abs/2506.19358
- 요약 (영문): electrocardiogram (ECG) has been successfully recovered from radar signals in the literature . but the performance heavily relies on the high-quality radar signal and numerous radar-ECG pairs for training . this work will focus on radar-based ECG recovery in new scenarios with limited data .
- 요약 (한글): 심전도(ECG)가 레이더 신호에서 성공적으로 복구된 사례도 있지만, 성능은 고품질 레이더 신호와 훈련용 수많은 레이더-ECG 쌍에 크게 의존합니다. 이 작업은 데이터가 제한된 새로운 시나리오에서 레이더 기반 ECG 복구에 초점을 맞출 것입니다.

### 85. Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation
- Authors: Jisu Shin, Juhyun Oh, Eunsu Kim, Hoyun Song, Alice Oh
- URL: https://arxiv.org/abs/2506.19352
- 요약 (영문): fidelity in large language models (LLMs) is essential for maintaining coherent and engaging human-AI interactions . however, generated responses deviate from an assigned persona, leading to inconsistencies .
- 요약 (한글): 대규모 언어 모델(LLM)의 충실도는 일관되고 매력적인 인간-AI 상호작용을 유지하는 데 필수적입니다. 그러나 생성된 응답이 할당된 페르소나에서 벗어나면 불일치가 발생하게 되고, 이는 일관성 결여로 이어집니다.

### 86. In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly
- Authors: Puneesh Deora, Bhavya Vasudeva, Tina Behnia, Christos Thrampoulidis
- URL: https://arxiv.org/abs/2506.19351
- 요약 (영문): in-context learning (ICL) enables transformers to adapt to new tasks through contextual examples without parameter updates . transformers navigate hierarchical task structures where higher-complexity categories can perfectly represent any pattern generated by simpler ones .
- 요약 (한글): 컨텍스트 내 학습(ICL)을 통해 트랜스포머는 파라미터 업데이트 없이 컨텍스트 예제를 통해 새로운 작업에 적응할 수 있습니다. 트랜스포머는 계층적 작업 구조를 탐색하여 더 복잡한 카테고리가 더 단순한 카테고리에서 생성된 모든 패턴을 완벽하게 나타낼 수 있습니다.

### 87. Discrepancy-Aware Graph Mask Auto-Encoder
- Authors: Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu
- URL: https://arxiv.org/abs/2506.19343
- 요약 (영문): Masked Graph Auto-Encoder has shown superior performance in graph representation learning . existing works typically rely on node contextual information to recover the masked information . they fail to generalize well to heterophilic graphs where connected nodes may be not similar .
- 요약 (한글): 마스크드 그래프 자동 인코더는 그래프 표현 학습에서 우수한 성능을 보였습니다. 기존 작업은 일반적으로 노드 컨텍스트 정보에 의존하여 마스크된 정보를 복구합니다. 연결된 노드가 유사하지 않을 수 있는 이종 그래프에는 잘 일반화하지 못합니다.

### 88. Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment
- Authors: Sudesh Bhagat, Raghupathi Kandiboina, Ibne Farabi Shihab, Skylar Knickerbocker, Neal Hawkins, Anuj Sharma
- URL: https://arxiv.org/abs/2506.19342
- 요약 (영문): road traffic crashes are a significant global cause of fatalities . a framework was developed to improve data quality in crash management systems and reduce the percentage of crashes .
- 요약 (한글): 도로 교통 충돌은 전 세계적으로 사망자의 중요한 원인입니다. 충돌 관리 시스템의 데이터 품질을 개선하고 충돌 발생률을 줄이기 위한 프레임워크가 개발되었습니다.

### 89. JCAPT: A Joint Modeling Approach for CAPT
- Authors: Tzu-Hsuan Yang, Yue-Yang He, Berlin Chen
- URL: https://arxiv.org/abs/2506.19315
- 요약 (영문): effective pronunciation feedback is critical in second language (L2) learning . automated pronunciation assessment (APA) and mispronunciation detection and diagnosis (MDD) can yield mutual benefits .
- 요약 (한글): 효과적인 발음 피드백은 제2외국어(L2) 학습에서 매우 중요합니다. 자동 발음 평가(APA)와 오발음 감지 및 진단(MDD)은 상호 이익을 가져올 수 있습니다.

### 90. Capturing Fine-Grained Alignments Improves 3D Affordance Detection
- Authors: Junsei Tokumitsu, Yuiga Wada
- URL: https://arxiv.org/abs/2506.19312
- 요약 (영문): reliance on simple cosine similarity between point clouds and text embeddings is a key limitation . reliance is limited on fine-grained reasoning and lacks expressiveness .
- 요약 (한글): 포인트 클라우드와 텍스트 임베딩 간의 단순한 코사인 유사성에 의존하는 것이 주요 한계입니다. 세분화된 추론에 의존하는 것은 제한적이며 표현력이 부족합니다.

### 91. AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration
- Authors: Xiangbo Gao, Yuheng Wu, Xuewen Luo, Keshu Wu, Xinghao Chen, Yuping Wang, Chenxi Liu, Yang Zhou, Zhengzhong Tu
- URL: https://arxiv.org/abs/2506.19283
- 요약 (영문): traditional infrastructure-based V2X systems remain constrained by deployment costs . a large-scale dataset leverages unmanned Aerial Vehicles (UAVs) as a flexible alternative .
- 요약 (한글): 기존 인프라 기반 V2X 시스템은 구축 비용의 제약을 받습니다. 대규모 데이터 세트는 무인 항공기(UAV)를 유연한 대안으로 활용합니다.

### 92. EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition
- Authors: Zhiyang Qi, Keiko Takamizo, Mariko Ukiyo, Michimasa Inaba
- URL: https://arxiv.org/abs/2506.19279
- 요약 (영문): the rising demand for mental health care has fueled interest in AI-driven counseling systems . current approaches face challenges including limited understanding of clients' psychological states and counseling stages, reliance on high-quality training data and privacy concerns associated with commercial deployment .
- 요약 (한글): 정신 건강 관리에 대한 수요가 증가하면서 AI 기반 상담 시스템에 대한 관심이 높아졌습니다. 현재의 접근 방식은 고객의 심리 상태 및 상담 단계에 대한 제한된 이해, 고품질 훈련 데이터에 대한 의존, 상업적 배포와 관련된 개인 정보 보호 문제 등의 문제에 직면해 있습니다.

### 93. AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation
- Authors: Ziyan Zhao, Ke Fan, He-Yang Xu, Ning Qiao, Bo Peng, Wenlong Gao, Dongjiang Li, Hui Shen
- URL: https://arxiv.org/abs/2506.19269
- 요약 (영문): anchorDP3 integrates three key innovations: 1) Simulator-Supervised Semantic Segmentation, 2) Task-Conditioned Feature Encoders, . lightweight modules processing augmented point clouds per task .
- 요약 (한글): anchorDP3는 세 가지 핵심 혁신을 통합합니다: 1) 시뮬레이터 감독 시맨틱 분할, 2) 작업별 증강 포인트 클라우드를 처리하는 경량 모듈인 작업 조건부 특징 인코더, .

### 94. Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization
- Authors: Boxuan Zhang, Zhen Xu, Kuan Tao
- URL: https://arxiv.org/abs/2506.19256
- 요약 (영문): Spiking Neural Networks (SNNs) have received widespread attention due to their event-driven and low-power characteristics . they suffer from severe overfitting issues due to the limited scale of neuromorphic datasets .
- 요약 (한글): 스파이킹 신경망(SNN)은 이벤트 기반 및 저전력 특성으로 인해 널리 주목을 받아왔지만, 뉴로모픽 데이터 세트의 제한된 규모로 인해 심각한 과적합 문제를 겪고 있습니다.

### 95. Robust Behavior Cloning Via Global Lipschitz Regularization
- Authors: Shili Wu, Yizhao Jin, Puhua Niu, Aniruddha Datta, Sean B. Andersson
- URL: https://arxiv.org/abs/2506.19250
- 요약 (영문): behavior cloning (BC) is an effective imitation learning technique . the policy observations may contain measurement errors or adversarial disturbances .
- 요약 (한글): 행동 복제(BC)는 효과적인 모방 학습 기법입니다. 정책 관찰에는 측정 오류 또는 적대적 교란이 포함될 수 있습니다.

### 96. Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification
- Authors: Minghao Qin, Xiangrui Liu, Zhengyang Liang, Yan Shu, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu
- URL: https://arxiv.org/abs/2506.19225
- 요약 (영문): multi-modal large language models have made significant progress in video understanding over the past few years . however, processing long video inputs remains a major challenge due to high memory and computational costs . to address this challenge, we propose Video-XL-2, a novel MLLM that delivers superior cost-effectiveness for long-video understanding based on task-aware tasks .
- 요약 (한글): 다중 모드 대규모 언어 모델은 지난 몇 년 동안 비디오 이해 분야에서 상당한 진전을 이루었지만, 긴 비디오 입력을 처리하는 것은 높은 메모리 및 계산 비용으로 인해 여전히 주요 과제로 남아 있습니다. 이 문제를 해결하기 위해 작업 인식 작업을 기반으로 긴 비디오 이해에 뛰어난 비용 효율성을 제공하는 새로운 MLLM인 Video-XL-2를 제안합니다.

### 97. Private Model Personalization Revisited
- Authors: Conor Snedeker, Xinyu Zhou, Raef Bassily
- URL: https://arxiv.org/abs/2506.19220
- 요약 (영문): we study model personalization under user-level differential privacy (DP) in the shared representation framework . there are $n$ users whose data is statistically heterogeneous . our goal is to privately recover the shared embedding and local low-dimensional representations .
- 요약 (한글): 공유 표현 프레임워크에서 사용자 수준 차등 프라이버시(DP) 하에서 모델 개인화를 연구합니다. 데이터가 통계적으로 이질적인 $n$명의 사용자가 있습니다. 우리의 목표는 공유 임베딩과 로컬 저차원 표현을 비공개적으로 복구하는 것입니다.

### 98. MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports
- Authors: Sunggu Kyung, Hyungbin Park, Jinyoung Seo, Jimin Sung, Jihyun Kim, Dongyeong Kim, Wooyoung Jo, Yoojin Nam, Sangah Park, Taehee Kwon, Sang Min Lee, Namkug Kim
- URL: https://arxiv.org/abs/2506.19217
- 요약 (영문): the growing demand for CT examinations has raised concerns about diagnostic errors . multimodal large language models (MLLMs) demonstrate promising comprehension of medical knowledge . existing medical visual question answering benchmarks focus on simple visual recognition tasks .
- 요약 (한글): CT 검사에 대한 수요가 증가함에 따라 진단 오류에 대한 우려가 높아졌습니다. 다중 모드 대규모 언어 모델(MLLM)은 의학 지식에 대한 유망한 이해력을 보여줍니다. 기존의 의료 시각 질문 답변 벤치마크는 단순한 시각 인식 작업에 초점을 맞추고 있습니다.
