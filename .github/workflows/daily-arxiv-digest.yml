name: Daily arXiv AI Papers Digest

on:
  schedule:
    - cron: '30 0 * * 1-5'  # 9:30 KST (UTC 00:30)
    - cron: '0 1 * * 1-5'   # 10:00 KST (UTC 01:00)
    - cron: '30 1 * * 1-5'  # 10:30 KST (UTC 01:30)
    - cron: '0 2 * * 1-5'   # 11:00 KST (UTC 02:00)
    - cron: '30 2 * * 1-5'  # 11:30 KST (UTC 02:30)
  workflow_dispatch: 

concurrency:
  group: arxiv-digest
  # [수정 1] true -> false로 변경 (중요!)
  cancel-in-progress: false

jobs:
  generate-and-send-digest:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Seoul
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create Google API credentials file
      run: |
        echo '${{ secrets.GOOGLE_API_CREDENTIALS }}' > google_credentials.json
        echo "GOOGLE_API_CREDENTIALS_PATH=google_credentials.json" >> $GITHUB_ENV
    
    - name: Set environment variables
      run: |
        echo "EMAIL_ADDRESS=${{ secrets.EMAIL_ADDRESS }}" >> $GITHUB_ENV
        echo "EMAIL_PASSWORD=${{ secrets.EMAIL_PASSWORD }}" >> $GITHUB_ENV
        echo "RECIPIENT=${{ secrets.RECIPIENT }}" >> $GITHUB_ENV
        echo "GOOGLE_SHEET_NAME=${{ secrets.GOOGLE_SHEET_NAME }}" >> $GITHUB_ENV
        echo "GOOGLE_WORKSHEET_NAME=${{ secrets.GOOGLE_WORKSHEET_NAME }}" >> $GITHUB_ENV
        echo "GOOGLE_SCRIPT_ID=${{ secrets.GOOGLE_SCRIPT_ID }}" >> $GITHUB_ENV
        echo "DEEPL_API_KEY=${{ secrets.DEEPL_API_KEY }}" >> $GITHUB_ENV
    
    - name: Check if already processed today (robust)
      id: check_status
      run: |
        TODAY=$(date +'%Y-%m-%d')
        echo "today=$TODAY" >> $GITHUB_OUTPUT

        JSON_PATH="results/arxiv_$(date +'%y%m%d').json"
        MD_PATH="digest/ALL/${TODAY}.md"
        EMAIL_STATUS_FILE="results/${TODAY}_email_sent.flag"

        git fetch origin arxiv-digest >/dev/null 2>&1

        # 1) 파일 및 플래그 존재 확인
        set +e
        git show origin/arxiv-digest:$JSON_PATH >/dev/null 2>&1; HAS_JSON=$?
        git show origin/arxiv-digest:$MD_PATH >/dev/null 2>&1; HAS_MD=$?
        git show origin/arxiv-digest:$EMAIL_STATUS_FILE >/dev/null 2>&1; HAS_FLAG=$?
        set -e

        # 다이제스트 파일 존재 여부 판단 (GitHub Pages 체크 포함)
        PAGES_URL="https://2shin0.github.io/arxiv-ai-mailing/ALL/${TODAY}.md"
        HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$PAGES_URL" || echo "000")

        if ([ $HAS_JSON -eq 0 ] && [ $HAS_MD -eq 0 ]) || [ "$HTTP_CODE" = "200" ]; then
          echo "files_exist=true" >> $GITHUB_OUTPUT
          echo "Today's digest files exist."
        else
          echo "files_exist=false" >> $GITHUB_OUTPUT
          echo "Digest files not found."
        fi

        # 이메일 발송 여부 판단
        if [ $HAS_FLAG -eq 0 ]; then
          echo "email_already_sent=true" >> $GITHUB_OUTPUT
          echo "Email already sent today."
        else
          echo "email_already_sent=false" >> $GITHUB_OUTPUT
          echo "Email not sent yet."
        fi
        
        # 전체 완료 여부 (파일도 있고 이메일도 보낸 경우에만 true)
        if (([ $HAS_JSON -eq 0 ] && [ $HAS_MD -eq 0 ]) || [ "$HTTP_CODE" = "200" ]) && [ $HAS_FLAG -eq 0 ]; then
          echo "already_processed=true" >> $GITHUB_OUTPUT
        else
          echo "already_processed=false" >> $GITHUB_OUTPUT
        fi

    - name: Run arXiv digest generation
      id: run_digest
      if: steps.check_status.outputs.files_exist == 'false'
      run: |
        echo "Starting arXiv digest generation..."
        START_TIME=$(date +'%Y-%m-%d %H:%M:%S')
        echo "start_time=$START_TIME" >> $GITHUB_OUTPUT
        
        if python main.py > execution.log 2>&1; then
          echo "success=true" >> $GITHUB_OUTPUT
          PAPER_COUNT=$(grep -E "Total papers found: [0-9]+" execution.log | tail -1 | grep -oE "[0-9]+" || echo "0")
          echo "paper_count=$PAPER_COUNT" >> $GITHUB_OUTPUT
        else
          echo "success=false" >> $GITHUB_OUTPUT
          cat execution.log
          exit 1
        fi
    
    - name: Configure Git
      # if 조건 수정: 논문 생성을 안 했더라도(이미 파일이 있는 경우), 배포가 안 되어 있을 수 있으므로 실행
      if: steps.run_digest.outputs.success == 'true' || steps.check_status.outputs.files_exist == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Deploy to GitHub Pages
      if: steps.run_digest.outputs.success == 'true' || steps.check_status.outputs.files_exist == 'true'
      id: deploy
      run: |
        echo "Deploying to GitHub Pages..."
        
        # 1. 생성된 최신 파일들을 임시 디렉토리에 백업 (만약 run_digest가 스킵됐다면 arxiv-digest에서 가져옴)
        mkdir -p ../temp_gen
        if [ "${{ steps.run_digest.outputs.success }}" == "true" ]; then
           cp -r results/ digest/ ../temp_gen/ 2>/dev/null || true
        else
           git checkout arxiv-digest
           cp -r results/ digest/ ../temp_gen/ 2>/dev/null || true
           git checkout main
        fi
        
        # 2. arxiv-digest 브랜치로 강제 전환 (데이터 백업용)
        git checkout -f arxiv-digest
        
        # 3. 백업된 최신 파일들을 가져오기
        cp -r ../temp_gen/digest/* . 2>/dev/null || true
        cp -r ../temp_gen/results . 2>/dev/null || true
        
        # 4. arxiv-digest 커밋/푸시
        git add ALL/ LLM/ results/
        if ! git diff --staged --quiet; then
          git commit -m "Add arXiv digest for ${{ steps.check_status.outputs.today }}"
          git push origin arxiv-digest --force
          echo "digest_deployed=true" >> $GITHUB_OUTPUT
        fi
        
        # 5. main 브랜치로 돌아와서 인덱스 페이지 업데이트
        git checkout -f main
        
        # [수정 2] main 브랜치에도 논문 파일(.md)을 복사해와야 합니다! (매우 중요)
        cp -r ../temp_gen/digest/* . 2>/dev/null || true
        
        # 인덱스 재생성
        python -c "from exporter import update_all_indexes; update_all_indexes()"
        
        # 인덱스 파일 뿐만 아니라 논문 폴더(LLM, ALL)도 함께 추가합니다.
        git add LLM/ ALL/
        
        if ! git diff --staged --quiet; then
          git commit -m "Update index pages and papers for ${{ steps.check_status.outputs.today }}"
          git push origin main
          echo "index_deployed=true" >> $GITHUB_OUTPUT
        fi
        echo "index_files_ready=true" >> $GITHUB_OUTPUT
    
    - name: Wait for GitHub Pages deployment
      if: steps.check_status.outputs.email_already_sent == 'false' && steps.deploy.outputs.index_files_ready == 'true'
      id: wait_pages
      run: |
        MAX_WAIT=600; WAIT_TIME=0; SLEEP_INTERVAL=20
        while [ $WAIT_TIME -lt $MAX_WAIT ]; do
          TODAY_FILE_URL="https://2shin0.github.io/arxiv-ai-mailing/ALL/${{ steps.check_status.outputs.today }}.md"
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$TODAY_FILE_URL")
          if [ "$HTTP_CODE" = "200" ]; then
            echo "pages_ready=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          sleep $SLEEP_INTERVAL; WAIT_TIME=$((WAIT_TIME + SLEEP_INTERVAL))
        done
        echo "pages_ready=false" >> $GITHUB_OUTPUT

    - name: Send email digest
      if: steps.check_status.outputs.email_already_sent == 'false' && steps.wait_pages.outputs.pages_ready == 'true'
      id: send_email
      run: |
        # JSON 파일을 arxiv-digest 브랜치에서 가져옴 (main에는 없을 수 있음)
        git fetch origin arxiv-digest
        mkdir -p results
        TODAY_SHORT=$(date +'%y%m%d')
        JSON_FILE="results/arxiv_${TODAY_SHORT}.json"
        
        git show origin/arxiv-digest:$JSON_FILE > $JSON_FILE 2>/dev/null || true
        
        # 파일이 없으면 로컬에서 찾기 (방금 생성된 경우)
        if [ ! -s "$JSON_FILE" ]; then
           cp ../temp_gen/results/arxiv_${TODAY_SHORT}.json $JSON_FILE 2>/dev/null || true
        fi

        if python send_digest.py > email.log 2>&1; then
          echo "email_sent=true" >> $GITHUB_OUTPUT
          
          # 플래그 생성 및 저장
          TODAY=$(date +'%Y-%m-%d')
          EMAIL_STATUS_FILE="results/${TODAY}_email_sent.flag"
          touch "$EMAIL_STATUS_FILE"
          
          # 플래그를 arxiv-digest 브랜치에 저장 (이력이 남도록)
          git checkout -f arxiv-digest
          git pull origin arxiv-digest --rebase || true
          git add "$EMAIL_STATUS_FILE"
          git commit -m "Add email sent flag for $TODAY" || true
          git push origin arxiv-digest
          
          # main으로 복귀
          git checkout main
        else
          echo "email_sent=false" >> $GITHUB_OUTPUT
          cat email.log
          exit 1
        fi
    
    - name: Create execution summary
      if: always()
      run: |
        echo "## Execution Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Date**: ${{ steps.check_status.outputs.today }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Status**: ${{ steps.check_status.outputs.already_processed == 'true' && 'Already Done' || 'Processed' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Email Sent**: ${{ steps.send_email.outputs.email_sent || steps.check_status.outputs.email_already_sent }}" >> $GITHUB_STEP_SUMMARY
    
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: logs-${{ steps.check_status.outputs.today }}
        path: |
          execution.log
          email.log
        retention-days: 7
    
    - name: Clean up credentials
      if: always()
      run: rm -f google_credentials.json
