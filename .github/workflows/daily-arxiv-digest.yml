name: Daily arXiv AI Papers Digest

on:
  schedule:
    - cron: '30 0 * * 1-5'  # 9:30 KST (UTC 00:30)
    - cron: '0 1 * * 1-5'   # 10:00 KST (UTC 01:00)
    - cron: '30 1 * * 1-5'  # 10:30 KST (UTC 01:30)
    - cron: '0 2 * * 1-5'   # 11:00 KST (UTC 02:00)
    - cron: '30 2 * * 1-5'  # 11:30 KST (UTC 02:30)
  workflow_dispatch: 

# 동시 실행 방지 설정
concurrency:
  group: arxiv-digest
  cancel-in-progress: true

jobs:
  generate-and-send-digest:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Seoul
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create Google API credentials file
      run: |
        echo '${{ secrets.GOOGLE_API_CREDENTIALS }}' > google_credentials.json
        echo "GOOGLE_API_CREDENTIALS_PATH=google_credentials.json" >> $GITHUB_ENV
    
    - name: Set environment variables
      run: |
        echo "EMAIL_ADDRESS=${{ secrets.EMAIL_ADDRESS }}" >> $GITHUB_ENV
        echo "EMAIL_PASSWORD=${{ secrets.EMAIL_PASSWORD }}" >> $GITHUB_ENV
        echo "RECIPIENT=${{ secrets.RECIPIENT }}" >> $GITHUB_ENV
        echo "GOOGLE_SHEET_NAME=${{ secrets.GOOGLE_SHEET_NAME }}" >> $GITHUB_ENV
        echo "GOOGLE_WORKSHEET_NAME=${{ secrets.GOOGLE_WORKSHEET_NAME }}" >> $GITHUB_ENV
        echo "GOOGLE_SCRIPT_ID=${{ secrets.GOOGLE_SCRIPT_ID }}" >> $GITHUB_ENV
        echo "DEEPL_API_KEY=${{ secrets.DEEPL_API_KEY }}" >> $GITHUB_ENV
    
    - name: Check if already processed today (robust)
      id: check_status
      run: |
        TODAY=$(date +'%Y-%m-%d')
        echo "today=$TODAY" >> $GITHUB_OUTPUT

        # 1) arxiv-digest 브랜치에서 오늘 파일 존재 여부 확인
        JSON_PATH="results/arxiv_$(date +'%y%m%d').json"
        MD_PATH="digest/ALL/${TODAY}.md"

        set +e
        git fetch origin arxiv-digest >/dev/null 2>&1
        git show origin/arxiv-digest:$JSON_PATH >/dev/null 2>&1
        HAS_JSON=$?
        git show origin/arxiv-digest:$MD_PATH >/dev/null 2>&1
        HAS_MD=$?
        set -e

        if [ $HAS_JSON -eq 0 ] && [ $HAS_MD -eq 0 ]; then
          echo "already_processed=true" >> $GITHUB_OUTPUT
          echo "Today's digest exists in arxiv-digest branch. Skipping."
          exit 0
        fi

        # 2) GH Pages에서 확인(배포 완료 후 재실행을 막기 위함)
        PAGES_URL="https://2shin0.github.io/arxiv-ai-mailing/ALL/${TODAY}.md"
        HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$PAGES_URL" || echo "000")
        if [ "$HTTP_CODE" = "200" ]; then
          echo "already_processed=true" >> $GITHUB_OUTPUT
          echo "Today's digest is already on GitHub Pages. Skipping."
          exit 0
        fi

        # 3) 플래그 파일(arxiv-digest 브랜치에서 확인)
        EMAIL_STATUS_FILE="results/${TODAY}_email_sent.flag"
        set +e
        git show origin/arxiv-digest:$EMAIL_STATUS_FILE >/dev/null 2>&1
        HAS_FLAG=$?
        set -e
        
        if [ $HAS_FLAG -eq 0 ]; then
          echo "already_processed=true" >> $GITHUB_OUTPUT
          echo "Email already sent today (flag exists in arxiv-digest branch). Skipping."
          exit 0
        fi

        echo "already_processed=false" >> $GITHUB_OUTPUT
        echo "No digest found for today. Proceeding with execution."

    - name: Run arXiv digest generation
      id: run_digest
      if: steps.check_status.outputs.already_processed == 'false'
      run: |
        echo "Starting arXiv digest generation..."
        
        # 실행 시작 시간 기록
        START_TIME=$(date +'%Y-%m-%d %H:%M:%S')
        echo "start_time=$START_TIME" >> $GITHUB_OUTPUT
        
        # main.py 실행 및 결과 캡처
        if python main.py > execution.log 2>&1; then
          echo "success=true" >> $GITHUB_OUTPUT
          echo "Digest generation completed successfully"
          
          # 생성된 논문 수 확인 (더 안정적인 방법)
          PAPER_COUNT=$(grep -E "Total papers found: [0-9]+" execution.log | tail -1 | grep -oE "[0-9]+" || echo "0")
          echo "paper_count=$PAPER_COUNT" >> $GITHUB_OUTPUT
          echo "Papers processed: $PAPER_COUNT"
          
          # 논문이 없는 경우 경고 표시
          if [ "$PAPER_COUNT" -eq "0" ]; then
            echo "Warning: No papers found for today"
            echo "warning=no_papers_found" >> $GITHUB_OUTPUT
            
            # 현재 시간 확인하여 다음 재시도 시간 계산
            CURRENT_HOUR=$(date +'%H')
            CURRENT_MIN=$(date +'%M')
            
            # 다음 실행 시간 계산 (KST 기준)
            if [ "$CURRENT_HOUR" -eq "9" ] && [ "$CURRENT_MIN" -ge "30" ]; then
              NEXT_TIME="10:00"
            elif [ "$CURRENT_HOUR" -eq "10" ] && [ "$CURRENT_MIN" -lt "30" ]; then
              NEXT_TIME="10:30"
            elif [ "$CURRENT_HOUR" -eq "10" ] && [ "$CURRENT_MIN" -ge "30" ]; then
              NEXT_TIME="11:00"
            elif [ "$CURRENT_HOUR" -eq "11" ] && [ "$CURRENT_MIN" -lt "30" ]; then
              NEXT_TIME="11:30"
            else
              NEXT_TIME="tomorrow 9:30"
            fi
            
            echo "No papers available. Will retry at $NEXT_TIME KST"
            echo "next_retry_time=$NEXT_TIME" >> $GITHUB_OUTPUT
          else
            echo "Successfully processed $PAPER_COUNT papers"
          fi
        else
          echo "success=false" >> $GITHUB_OUTPUT
          echo "Digest generation failed"
          
          # 에러 로그 출력
          echo "=== ERROR LOG ==="
          cat execution.log
          echo "================="
          
          # 실패 이유 분석 (더 정확한 패턴 매칭)
          if grep -qE "(No papers found|0 papers)" execution.log; then
            echo "error_reason=no_papers_available" >> $GITHUB_OUTPUT
          elif grep -qE "(Failed to fetch|Connection|Network|HTTP)" execution.log; then
            echo "error_reason=network_error" >> $GITHUB_OUTPUT
          elif grep -qE "(API|Authentication|Credentials)" execution.log; then
            echo "error_reason=api_error" >> $GITHUB_OUTPUT
          elif grep -qE "(Permission|Access)" execution.log; then
            echo "error_reason=permission_error" >> $GITHUB_OUTPUT
          else
            echo "error_reason=unknown_error" >> $GITHUB_OUTPUT
          fi
          
          exit 1
        fi
    
    - name: Configure Git
      if: steps.run_digest.outputs.success == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Deploy to GitHub Pages
      if: steps.run_digest.outputs.success == 'true'
      id: deploy
      run: |
        echo "Deploying to GitHub Pages..."
        
        # arxiv-digest 브랜치로 전환하여 다이제스트 파일들 커밋
        git checkout -B arxiv-digest
        
        # digest 폴더가 존재하는 경우에만 추가
        if [ -d "digest" ]; then
          git add digest/
          echo "Added digest folder"
        else
          echo "Warning: digest folder not found"
        fi
        
        # results 폴더가 존재하는 경우에만 추가
        if [ -d "results" ]; then
          git add results/
          echo "Added results folder"
        else
          echo "Warning: results folder not found"
        fi
        
        # 변경사항이 있는 경우에만 커밋
        if ! git diff --staged --quiet; then
          git commit -m "Add arXiv digest for ${{ steps.check_status.outputs.today }} (Papers: ${{ steps.run_digest.outputs.paper_count }})"
          git push origin arxiv-digest --force
          echo "digest_deployed=true" >> $GITHUB_OUTPUT
        else
          echo "digest_deployed=false" >> $GITHUB_OUTPUT
          echo "No changes to deploy in digest branch"
        fi
        
        # main 브랜치로 전환하여 인덱스 파일들 업데이트
        git checkout main
        
        # 인덱스 페이지 업데이트 (Python으로 직접 실행)
        if [ -d "digest" ]; then
          python -c "from exporter import update_all_indexes; import os; update_all_indexes(); print('Index pages updated successfully')"
        else
          echo "Skipping index update - digest directory not found"
        fi
        
        # 인덱스 파일들이 존재하는 경우에만 추가
        if [ -f "LLM/index.md" ]; then
          git add LLM/index.md
          echo "Added LLM/index.md"
        fi
        
        if [ -f "ALL/index.md" ]; then
          git add ALL/index.md  
          echo "Added ALL/index.md"
        fi
        
        # 변경사항이 있는 경우에만 커밋
        if ! git diff --staged --quiet; then
          git commit -m "Update index pages for ${{ steps.check_status.outputs.today }}"
          git push origin main
          echo "index_deployed=true" >> $GITHUB_OUTPUT
        else
          echo "index_deployed=false" >> $GITHUB_OUTPUT
          echo "No changes to deploy in main branch"
        fi
        
        # 인덱스 배포 상태를 전역 출력으로 설정
        if [ -f "LLM/index.md" ] && [ -f "ALL/index.md" ]; then
          echo "index_files_ready=true" >> $GITHUB_OUTPUT
        else
          echo "index_files_ready=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Wait for GitHub Pages deployment
      if: steps.run_digest.outputs.success == 'true' && steps.deploy.outputs.digest_deployed == 'true'
      id: wait_pages
      run: |
        echo "Waiting for GitHub Pages deployment to complete..."
        
        # GitHub Pages 배포 완료까지 최대 10분 대기
        MAX_WAIT=600  # 10분
        WAIT_TIME=0
        SLEEP_INTERVAL=20  # 20초마다 확인
        
        while [ $WAIT_TIME -lt $MAX_WAIT ]; do
          echo "Checking deployment status... (${WAIT_TIME}s elapsed)"
          
          # GitHub Pages 상태 확인 (오늘 날짜의 다이제스트 파일이 실제로 배포되었는지 확인)
          TODAY_FILE_URL="https://2shin0.github.io/arxiv-ai-mailing/ALL/${{ steps.check_status.outputs.today }}.md"
          echo "Checking for file at: $TODAY_FILE_URL"
          
          # HTTP 상태 코드 확인
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$TODAY_FILE_URL")
          echo "HTTP response code: $HTTP_CODE"
          
          if [ "$HTTP_CODE" = "200" ]; then
            echo "GitHub Pages deployment completed successfully!"
            echo "pages_ready=true" >> $GITHUB_OUTPUT
            break
          elif [ "$HTTP_CODE" = "404" ]; then
            echo "File not yet available (404). Continuing to wait..."
          else
            echo "Unexpected response code: $HTTP_CODE. Continuing to wait..."
          fi
          
          # 5분 후부터는 인덱스 페이지도 확인 (대체 확인 방법)
          if [ $WAIT_TIME -ge 300 ]; then
            INDEX_URL="https://2shin0.github.io/arxiv-ai-mailing/ALL/"
            INDEX_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$INDEX_URL")
            echo "Also checking index page: $INDEX_CODE"
            
            if [ "$INDEX_CODE" = "200" ]; then
              # 인덱스 페이지가 업데이트되었는지 확인 (오늘 날짜 포함 여부)
              if curl -s "$INDEX_URL" | grep -q "${{ steps.check_status.outputs.today }}"; then
                echo "Index page updated with today's content. Assuming deployment is ready."
                echo "pages_ready=true" >> $GITHUB_OUTPUT
                break
              fi
            fi
          fi
          
          sleep $SLEEP_INTERVAL
          WAIT_TIME=$((WAIT_TIME + SLEEP_INTERVAL))
        done
        
        if [ $WAIT_TIME -ge $MAX_WAIT ]; then
          echo "Timeout waiting for GitHub Pages deployment"
          echo "pages_ready=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Send email digest
      if: steps.run_digest.outputs.success == 'true' && steps.deploy.outputs.digest_deployed == 'true' && steps.deploy.outputs.index_files_ready == 'true' && steps.wait_pages.outputs.pages_ready == 'true'
      id: send_email
      run: |
        echo "Sending email digest..."
        
        # arxiv-digest 브랜치에서 JSON 파일을 main 브랜치로 복사
        echo "Copying JSON file from arxiv-digest branch..."
        git fetch origin arxiv-digest

        mkdir -p results
        
        # 오늘 날짜의 JSON 파일을 arxiv-digest 브랜치에서 복사
        TODAY=$(date +'%y%m%d')
        JSON_FILE="results/arxiv_${TODAY}.json"
        
        if git show origin/arxiv-digest:$JSON_FILE > $JSON_FILE 2>/dev/null; then
          echo "Successfully copied JSON file: $JSON_FILE"
          
          if python send_digest.py > email.log 2>&1; then
            echo "email_sent=true" >> $GITHUB_OUTPUT
            echo "Email sent successfully"

            rm -f "$JSON_FILE"
            
            # 메일 발송 성공 시 상태 파일 생성 및 커밋
            TODAY=$(date +'%Y-%m-%d')
            EMAIL_STATUS_FILE="results/${TODAY}_email_sent.flag"
            touch "$EMAIL_STATUS_FILE"
            echo "Created flag file: $EMAIL_STATUS_FILE"

            # 플래그 파일을 arxiv-digest 브랜치에 커밋하여 영속화
            git checkout arxiv-digest
            git add "$EMAIL_STATUS_FILE"
            git commit -m "Add email sent flag for $TODAY" || echo "Flag file already exists"
            git push origin arxiv-digest
            git checkout main
            echo "Flag file committed to arxiv-digest branch"
          else
            echo "email_sent=false" >> $GITHUB_OUTPUT
            echo "Failed to send email"
            echo "=== EMAIL ERROR LOG ==="
            cat email.log
            echo "======================="
          fi
        else
          echo "email_sent=false" >> $GITHUB_OUTPUT
          echo "Failed to copy JSON file from arxiv-digest branch"
          echo "=== EMAIL ERROR LOG ===" > email.log
          echo "JSON 파일을 arxiv-digest 브랜치에서 복사할 수 없습니다: $JSON_FILE" >> email.log
          echo "======================="
          cat email.log
        fi
    
    - name: Create execution summary
      if: always()
      run: |
        echo "## Execution Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Date**: ${{ steps.check_status.outputs.today }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Time**: $(date +'%H:%M:%S KST')" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.check_status.outputs.already_processed }}" == "true" ]; then
          echo "- **Status**: Skipped (already processed)" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ steps.run_digest.outputs.success }}" == "true" ]; then
          echo "- **Status**: Success" >> $GITHUB_STEP_SUMMARY
          echo "- **Papers Found**: ${{ steps.run_digest.outputs.paper_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Digest Deployed**: ${{ steps.deploy.outputs.digest_deployed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Index Updated**: ${{ steps.deploy.outputs.index_deployed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Pages Ready**: ${{ steps.wait_pages.outputs.pages_ready }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Email Sent**: ${{ steps.send_email.outputs.email_sent }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.run_digest.outputs.warning }}" == "no_papers_found" ]; then
            echo "- **Warning**: No papers found for today" >> $GITHUB_STEP_SUMMARY
            echo "- **Next Retry**: ${{ steps.run_digest.outputs.next_retry_time }} KST" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "- **Status**: Failed" >> $GITHUB_STEP_SUMMARY
          echo "- **Error Reason**: ${{ steps.run_digest.outputs.error_reason }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Next Retry**: $(date -d '+1 hour' +'%H:%M KST')" >> $GITHUB_STEP_SUMMARY
        fi
        
        # 배포 실패 시 재시도 알림
        if [ "${{ steps.run_digest.outputs.success }}" == "true" ] && [ "${{ steps.deploy.outputs.digest_deployed }}" != "true" ] && [ "${{ steps.deploy.outputs.index_deployed }}" != "true" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ **Deployment Failed**: Email not sent. Will retry at next scheduled time." >> $GITHUB_STEP_SUMMARY
          echo "- **Retry Schedule**: Next execution at $(date -d 'tomorrow' +'%Y-%m-%d') 10:00 KST" >> $GITHUB_STEP_SUMMARY
        fi
        
        # GitHub Pages 배포 대기 타임아웃 시 알림
        if [ "${{ steps.wait_pages.outputs.pages_ready }}" == "false" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ **Pages Deployment Timeout**: Email not sent due to deployment delay." >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: Pages may still be deploying. Check manually." >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Upload execution log
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: execution-log-${{ steps.check_status.outputs.today }}
        path: execution.log
        retention-days: 7
    
    - name: Upload email log
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: email-log-${{ steps.check_status.outputs.today }}
        path: email.log
        retention-days: 7
    
    - name: Clean up credentials
      if: always()
      run: |
        rm -f google_credentials.json
